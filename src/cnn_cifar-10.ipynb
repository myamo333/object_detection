{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "CNN(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 訓練に際して、可能であればGPU（cuda）を設定します。GPUが搭載されていない場合はCPUを使用します\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# CNNモデルの定義\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    # T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 訓練データをdatasetsからダウンロード\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# テストデータをdatasetsからダウンロード\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([4, 3, 32, 32])\n",
      "Shape of y:  torch.Size([4]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "# データローダーの作成\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.282524  [    0/50000]\n",
      "loss: 2.214510  [  400/50000]\n",
      "loss: 2.209107  [  800/50000]\n",
      "loss: 2.305845  [ 1200/50000]\n",
      "loss: 2.254108  [ 1600/50000]\n",
      "loss: 2.293937  [ 2000/50000]\n",
      "loss: 2.308123  [ 2400/50000]\n",
      "loss: 2.372203  [ 2800/50000]\n",
      "loss: 2.261523  [ 3200/50000]\n",
      "loss: 2.281411  [ 3600/50000]\n",
      "loss: 2.337302  [ 4000/50000]\n",
      "loss: 2.321142  [ 4400/50000]\n",
      "loss: 2.359768  [ 4800/50000]\n",
      "loss: 2.311946  [ 5200/50000]\n",
      "loss: 2.271067  [ 5600/50000]\n",
      "loss: 2.274000  [ 6000/50000]\n",
      "loss: 2.307652  [ 6400/50000]\n",
      "loss: 2.281654  [ 6800/50000]\n",
      "loss: 2.293721  [ 7200/50000]\n",
      "loss: 2.327312  [ 7600/50000]\n",
      "loss: 2.292226  [ 8000/50000]\n",
      "loss: 2.326719  [ 8400/50000]\n",
      "loss: 2.312625  [ 8800/50000]\n",
      "loss: 2.303690  [ 9200/50000]\n",
      "loss: 2.272534  [ 9600/50000]\n",
      "loss: 2.322595  [10000/50000]\n",
      "loss: 2.315345  [10400/50000]\n",
      "loss: 2.266666  [10800/50000]\n",
      "loss: 2.297393  [11200/50000]\n",
      "loss: 2.283367  [11600/50000]\n",
      "loss: 2.269222  [12000/50000]\n",
      "loss: 2.338009  [12400/50000]\n",
      "loss: 2.347287  [12800/50000]\n",
      "loss: 2.290981  [13200/50000]\n",
      "loss: 2.278413  [13600/50000]\n",
      "loss: 2.319439  [14000/50000]\n",
      "loss: 2.316148  [14400/50000]\n",
      "loss: 2.295241  [14800/50000]\n",
      "loss: 2.298734  [15200/50000]\n",
      "loss: 2.308696  [15600/50000]\n",
      "loss: 2.284179  [16000/50000]\n",
      "loss: 2.288353  [16400/50000]\n",
      "loss: 2.319022  [16800/50000]\n",
      "loss: 2.277211  [17200/50000]\n",
      "loss: 2.284130  [17600/50000]\n",
      "loss: 2.284678  [18000/50000]\n",
      "loss: 2.302369  [18400/50000]\n",
      "loss: 2.276589  [18800/50000]\n",
      "loss: 2.310695  [19200/50000]\n",
      "loss: 2.292212  [19600/50000]\n",
      "loss: 2.314403  [20000/50000]\n",
      "loss: 2.279833  [20400/50000]\n",
      "loss: 2.269741  [20800/50000]\n",
      "loss: 2.296827  [21200/50000]\n",
      "loss: 2.307988  [21600/50000]\n",
      "loss: 2.311253  [22000/50000]\n",
      "loss: 2.316795  [22400/50000]\n",
      "loss: 2.269497  [22800/50000]\n",
      "loss: 2.314878  [23200/50000]\n",
      "loss: 2.300048  [23600/50000]\n",
      "loss: 2.268900  [24000/50000]\n",
      "loss: 2.285524  [24400/50000]\n",
      "loss: 2.232655  [24800/50000]\n",
      "loss: 2.296513  [25200/50000]\n",
      "loss: 2.311248  [25600/50000]\n",
      "loss: 2.265141  [26000/50000]\n",
      "loss: 2.290034  [26400/50000]\n",
      "loss: 2.265985  [26800/50000]\n",
      "loss: 2.235980  [27200/50000]\n",
      "loss: 2.281982  [27600/50000]\n",
      "loss: 2.285971  [28000/50000]\n",
      "loss: 2.291017  [28400/50000]\n",
      "loss: 2.336725  [28800/50000]\n",
      "loss: 2.318364  [29200/50000]\n",
      "loss: 2.294228  [29600/50000]\n",
      "loss: 2.249443  [30000/50000]\n",
      "loss: 2.250695  [30400/50000]\n",
      "loss: 2.312183  [30800/50000]\n",
      "loss: 2.248175  [31200/50000]\n",
      "loss: 2.365784  [31600/50000]\n",
      "loss: 2.262495  [32000/50000]\n",
      "loss: 2.197784  [32400/50000]\n",
      "loss: 2.364508  [32800/50000]\n",
      "loss: 2.286590  [33200/50000]\n",
      "loss: 2.290273  [33600/50000]\n",
      "loss: 2.249528  [34000/50000]\n",
      "loss: 2.310729  [34400/50000]\n",
      "loss: 2.279025  [34800/50000]\n",
      "loss: 2.115254  [35200/50000]\n",
      "loss: 2.336228  [35600/50000]\n",
      "loss: 2.113210  [36000/50000]\n",
      "loss: 2.287549  [36400/50000]\n",
      "loss: 2.152930  [36800/50000]\n",
      "loss: 2.277087  [37200/50000]\n",
      "loss: 2.240713  [37600/50000]\n",
      "loss: 1.737568  [38000/50000]\n",
      "loss: 2.185425  [38400/50000]\n",
      "loss: 2.066997  [38800/50000]\n",
      "loss: 1.925376  [39200/50000]\n",
      "loss: 2.236048  [39600/50000]\n",
      "loss: 2.280788  [40000/50000]\n",
      "loss: 2.138293  [40400/50000]\n",
      "loss: 2.476078  [40800/50000]\n",
      "loss: 1.783259  [41200/50000]\n",
      "loss: 2.347490  [41600/50000]\n",
      "loss: 2.152163  [42000/50000]\n",
      "loss: 2.083319  [42400/50000]\n",
      "loss: 2.130197  [42800/50000]\n",
      "loss: 2.092774  [43200/50000]\n",
      "loss: 2.059411  [43600/50000]\n",
      "loss: 2.299621  [44000/50000]\n",
      "loss: 2.102192  [44400/50000]\n",
      "loss: 2.157785  [44800/50000]\n",
      "loss: 2.468864  [45200/50000]\n",
      "loss: 2.127927  [45600/50000]\n",
      "loss: 1.965116  [46000/50000]\n",
      "loss: 2.176698  [46400/50000]\n",
      "loss: 2.477485  [46800/50000]\n",
      "loss: 1.940749  [47200/50000]\n",
      "loss: 1.976897  [47600/50000]\n",
      "loss: 1.870054  [48000/50000]\n",
      "loss: 1.983843  [48400/50000]\n",
      "loss: 2.336180  [48800/50000]\n",
      "loss: 1.906440  [49200/50000]\n",
      "loss: 1.850056  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 23.1%, Avg loss: 0.520541 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.774706  [    0/50000]\n",
      "loss: 2.086957  [  400/50000]\n",
      "loss: 2.225308  [  800/50000]\n",
      "loss: 2.173935  [ 1200/50000]\n",
      "loss: 1.640528  [ 1600/50000]\n",
      "loss: 1.983741  [ 2000/50000]\n",
      "loss: 1.632732  [ 2400/50000]\n",
      "loss: 1.830834  [ 2800/50000]\n",
      "loss: 2.002517  [ 3200/50000]\n",
      "loss: 2.139668  [ 3600/50000]\n",
      "loss: 1.855287  [ 4000/50000]\n",
      "loss: 2.027534  [ 4400/50000]\n",
      "loss: 2.048595  [ 4800/50000]\n",
      "loss: 2.178117  [ 5200/50000]\n",
      "loss: 1.758598  [ 5600/50000]\n",
      "loss: 1.705297  [ 6000/50000]\n",
      "loss: 1.809739  [ 6400/50000]\n",
      "loss: 2.281039  [ 6800/50000]\n",
      "loss: 2.253186  [ 7200/50000]\n",
      "loss: 2.341458  [ 7600/50000]\n",
      "loss: 2.034647  [ 8000/50000]\n",
      "loss: 2.345216  [ 8400/50000]\n",
      "loss: 2.515147  [ 8800/50000]\n",
      "loss: 2.098009  [ 9200/50000]\n",
      "loss: 2.257262  [ 9600/50000]\n",
      "loss: 2.275217  [10000/50000]\n",
      "loss: 1.568929  [10400/50000]\n",
      "loss: 2.150901  [10800/50000]\n",
      "loss: 2.187983  [11200/50000]\n",
      "loss: 1.901081  [11600/50000]\n",
      "loss: 2.067420  [12000/50000]\n",
      "loss: 1.578987  [12400/50000]\n",
      "loss: 1.917458  [12800/50000]\n",
      "loss: 1.858336  [13200/50000]\n",
      "loss: 1.785314  [13600/50000]\n",
      "loss: 2.021679  [14000/50000]\n",
      "loss: 2.039441  [14400/50000]\n",
      "loss: 1.881603  [14800/50000]\n",
      "loss: 2.346722  [15200/50000]\n",
      "loss: 2.222814  [15600/50000]\n",
      "loss: 2.204014  [16000/50000]\n",
      "loss: 2.196478  [16400/50000]\n",
      "loss: 1.778475  [16800/50000]\n",
      "loss: 1.977700  [17200/50000]\n",
      "loss: 1.737827  [17600/50000]\n",
      "loss: 1.777149  [18000/50000]\n",
      "loss: 1.947288  [18400/50000]\n",
      "loss: 1.530794  [18800/50000]\n",
      "loss: 1.804801  [19200/50000]\n",
      "loss: 1.694415  [19600/50000]\n",
      "loss: 2.983298  [20000/50000]\n",
      "loss: 2.151260  [20400/50000]\n",
      "loss: 1.464597  [20800/50000]\n",
      "loss: 1.965806  [21200/50000]\n",
      "loss: 1.865964  [21600/50000]\n",
      "loss: 2.100349  [22000/50000]\n",
      "loss: 1.986431  [22400/50000]\n",
      "loss: 1.789821  [22800/50000]\n",
      "loss: 2.600551  [23200/50000]\n",
      "loss: 1.439797  [23600/50000]\n",
      "loss: 1.528310  [24000/50000]\n",
      "loss: 1.483553  [24400/50000]\n",
      "loss: 1.423840  [24800/50000]\n",
      "loss: 1.956951  [25200/50000]\n",
      "loss: 2.339442  [25600/50000]\n",
      "loss: 1.659388  [26000/50000]\n",
      "loss: 2.378213  [26400/50000]\n",
      "loss: 1.746858  [26800/50000]\n",
      "loss: 1.845498  [27200/50000]\n",
      "loss: 1.804314  [27600/50000]\n",
      "loss: 2.278491  [28000/50000]\n",
      "loss: 2.738166  [28400/50000]\n",
      "loss: 2.352573  [28800/50000]\n",
      "loss: 1.854387  [29200/50000]\n",
      "loss: 2.097329  [29600/50000]\n",
      "loss: 1.595383  [30000/50000]\n",
      "loss: 1.663881  [30400/50000]\n",
      "loss: 1.944656  [30800/50000]\n",
      "loss: 1.470393  [31200/50000]\n",
      "loss: 2.566807  [31600/50000]\n",
      "loss: 1.747404  [32000/50000]\n",
      "loss: 1.543883  [32400/50000]\n",
      "loss: 2.404528  [32800/50000]\n",
      "loss: 1.820330  [33200/50000]\n",
      "loss: 2.177124  [33600/50000]\n",
      "loss: 2.013635  [34000/50000]\n",
      "loss: 1.632654  [34400/50000]\n",
      "loss: 1.767914  [34800/50000]\n",
      "loss: 1.703928  [35200/50000]\n",
      "loss: 2.286977  [35600/50000]\n",
      "loss: 1.577028  [36000/50000]\n",
      "loss: 1.992035  [36400/50000]\n",
      "loss: 1.758585  [36800/50000]\n",
      "loss: 1.576039  [37200/50000]\n",
      "loss: 1.384207  [37600/50000]\n",
      "loss: 1.488387  [38000/50000]\n",
      "loss: 2.087790  [38400/50000]\n",
      "loss: 1.784043  [38800/50000]\n",
      "loss: 1.481988  [39200/50000]\n",
      "loss: 1.352181  [39600/50000]\n",
      "loss: 1.291301  [40000/50000]\n",
      "loss: 2.140620  [40400/50000]\n",
      "loss: 2.172419  [40800/50000]\n",
      "loss: 1.037570  [41200/50000]\n",
      "loss: 2.057659  [41600/50000]\n",
      "loss: 1.903919  [42000/50000]\n",
      "loss: 1.669878  [42400/50000]\n",
      "loss: 1.755714  [42800/50000]\n",
      "loss: 1.722165  [43200/50000]\n",
      "loss: 1.613928  [43600/50000]\n",
      "loss: 1.672506  [44000/50000]\n",
      "loss: 1.432068  [44400/50000]\n",
      "loss: 1.915940  [44800/50000]\n",
      "loss: 2.175997  [45200/50000]\n",
      "loss: 1.386953  [45600/50000]\n",
      "loss: 1.568775  [46000/50000]\n",
      "loss: 2.374233  [46400/50000]\n",
      "loss: 2.253569  [46800/50000]\n",
      "loss: 1.938608  [47200/50000]\n",
      "loss: 1.544334  [47600/50000]\n",
      "loss: 2.289891  [48000/50000]\n",
      "loss: 1.626455  [48400/50000]\n",
      "loss: 2.498921  [48800/50000]\n",
      "loss: 1.345238  [49200/50000]\n",
      "loss: 1.701756  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.8%, Avg loss: 0.444141 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.488316  [    0/50000]\n",
      "loss: 2.226584  [  400/50000]\n",
      "loss: 2.022723  [  800/50000]\n",
      "loss: 2.343727  [ 1200/50000]\n",
      "loss: 1.090437  [ 1600/50000]\n",
      "loss: 1.681293  [ 2000/50000]\n",
      "loss: 1.242257  [ 2400/50000]\n",
      "loss: 1.348207  [ 2800/50000]\n",
      "loss: 2.184784  [ 3200/50000]\n",
      "loss: 1.536220  [ 3600/50000]\n",
      "loss: 1.389944  [ 4000/50000]\n",
      "loss: 1.759578  [ 4400/50000]\n",
      "loss: 1.633974  [ 4800/50000]\n",
      "loss: 1.561434  [ 5200/50000]\n",
      "loss: 1.265073  [ 5600/50000]\n",
      "loss: 1.501104  [ 6000/50000]\n",
      "loss: 1.642107  [ 6400/50000]\n",
      "loss: 1.851344  [ 6800/50000]\n",
      "loss: 2.041584  [ 7200/50000]\n",
      "loss: 1.683393  [ 7600/50000]\n",
      "loss: 1.492548  [ 8000/50000]\n",
      "loss: 2.344549  [ 8400/50000]\n",
      "loss: 2.381765  [ 8800/50000]\n",
      "loss: 1.644796  [ 9200/50000]\n",
      "loss: 1.765624  [ 9600/50000]\n",
      "loss: 2.229099  [10000/50000]\n",
      "loss: 0.992117  [10400/50000]\n",
      "loss: 1.732229  [10800/50000]\n",
      "loss: 2.265138  [11200/50000]\n",
      "loss: 2.090200  [11600/50000]\n",
      "loss: 2.055282  [12000/50000]\n",
      "loss: 1.719925  [12400/50000]\n",
      "loss: 1.637711  [12800/50000]\n",
      "loss: 1.741670  [13200/50000]\n",
      "loss: 2.050108  [13600/50000]\n",
      "loss: 2.170849  [14000/50000]\n",
      "loss: 1.551417  [14400/50000]\n",
      "loss: 1.935344  [14800/50000]\n",
      "loss: 1.857928  [15200/50000]\n",
      "loss: 2.356166  [15600/50000]\n",
      "loss: 1.828876  [16000/50000]\n",
      "loss: 2.171661  [16400/50000]\n",
      "loss: 1.657309  [16800/50000]\n",
      "loss: 2.142105  [17200/50000]\n",
      "loss: 1.343216  [17600/50000]\n",
      "loss: 1.582551  [18000/50000]\n",
      "loss: 1.737930  [18400/50000]\n",
      "loss: 1.156125  [18800/50000]\n",
      "loss: 1.336823  [19200/50000]\n",
      "loss: 1.515498  [19600/50000]\n",
      "loss: 2.600827  [20000/50000]\n",
      "loss: 1.688718  [20400/50000]\n",
      "loss: 1.538458  [20800/50000]\n",
      "loss: 1.946390  [21200/50000]\n",
      "loss: 1.174684  [21600/50000]\n",
      "loss: 1.388170  [22000/50000]\n",
      "loss: 1.930123  [22400/50000]\n",
      "loss: 1.904843  [22800/50000]\n",
      "loss: 2.552875  [23200/50000]\n",
      "loss: 1.012475  [23600/50000]\n",
      "loss: 1.227156  [24000/50000]\n",
      "loss: 1.210541  [24400/50000]\n",
      "loss: 1.178018  [24800/50000]\n",
      "loss: 1.447529  [25200/50000]\n",
      "loss: 1.979410  [25600/50000]\n",
      "loss: 1.636697  [26000/50000]\n",
      "loss: 2.690046  [26400/50000]\n",
      "loss: 1.866342  [26800/50000]\n",
      "loss: 1.585299  [27200/50000]\n",
      "loss: 2.259146  [27600/50000]\n",
      "loss: 1.846268  [28000/50000]\n",
      "loss: 2.561026  [28400/50000]\n",
      "loss: 2.059575  [28800/50000]\n",
      "loss: 1.619777  [29200/50000]\n",
      "loss: 1.421135  [29600/50000]\n",
      "loss: 1.635555  [30000/50000]\n",
      "loss: 1.602676  [30400/50000]\n",
      "loss: 1.525543  [30800/50000]\n",
      "loss: 1.110426  [31200/50000]\n",
      "loss: 2.261701  [31600/50000]\n",
      "loss: 1.195908  [32000/50000]\n",
      "loss: 1.188660  [32400/50000]\n",
      "loss: 2.205574  [32800/50000]\n",
      "loss: 1.450552  [33200/50000]\n",
      "loss: 1.746257  [33600/50000]\n",
      "loss: 1.875624  [34000/50000]\n",
      "loss: 1.205215  [34400/50000]\n",
      "loss: 1.787903  [34800/50000]\n",
      "loss: 1.594399  [35200/50000]\n",
      "loss: 1.699821  [35600/50000]\n",
      "loss: 1.355895  [36000/50000]\n",
      "loss: 1.758872  [36400/50000]\n",
      "loss: 1.154613  [36800/50000]\n",
      "loss: 1.005725  [37200/50000]\n",
      "loss: 1.088083  [37600/50000]\n",
      "loss: 1.232387  [38000/50000]\n",
      "loss: 1.771450  [38400/50000]\n",
      "loss: 1.484333  [38800/50000]\n",
      "loss: 1.576134  [39200/50000]\n",
      "loss: 1.147431  [39600/50000]\n",
      "loss: 0.757415  [40000/50000]\n",
      "loss: 1.907331  [40400/50000]\n",
      "loss: 1.628840  [40800/50000]\n",
      "loss: 0.965299  [41200/50000]\n",
      "loss: 1.638838  [41600/50000]\n",
      "loss: 1.841506  [42000/50000]\n",
      "loss: 1.427421  [42400/50000]\n",
      "loss: 1.714505  [42800/50000]\n",
      "loss: 1.460452  [43200/50000]\n",
      "loss: 1.147151  [43600/50000]\n",
      "loss: 1.748094  [44000/50000]\n",
      "loss: 1.057680  [44400/50000]\n",
      "loss: 1.906988  [44800/50000]\n",
      "loss: 1.639372  [45200/50000]\n",
      "loss: 1.083587  [45600/50000]\n",
      "loss: 1.283631  [46000/50000]\n",
      "loss: 2.535672  [46400/50000]\n",
      "loss: 1.980008  [46800/50000]\n",
      "loss: 2.081791  [47200/50000]\n",
      "loss: 1.199511  [47600/50000]\n",
      "loss: 2.469239  [48000/50000]\n",
      "loss: 1.425842  [48400/50000]\n",
      "loss: 2.081195  [48800/50000]\n",
      "loss: 1.087778  [49200/50000]\n",
      "loss: 1.506457  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.386289 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.359580  [    0/50000]\n",
      "loss: 2.213148  [  400/50000]\n",
      "loss: 1.966115  [  800/50000]\n",
      "loss: 2.284080  [ 1200/50000]\n",
      "loss: 1.008955  [ 1600/50000]\n",
      "loss: 1.245472  [ 2000/50000]\n",
      "loss: 1.071346  [ 2400/50000]\n",
      "loss: 1.282363  [ 2800/50000]\n",
      "loss: 2.327929  [ 3200/50000]\n",
      "loss: 1.268761  [ 3600/50000]\n",
      "loss: 0.998749  [ 4000/50000]\n",
      "loss: 1.356489  [ 4400/50000]\n",
      "loss: 1.935471  [ 4800/50000]\n",
      "loss: 1.236908  [ 5200/50000]\n",
      "loss: 1.023616  [ 5600/50000]\n",
      "loss: 1.421628  [ 6000/50000]\n",
      "loss: 1.764065  [ 6400/50000]\n",
      "loss: 1.792155  [ 6800/50000]\n",
      "loss: 1.486014  [ 7200/50000]\n",
      "loss: 1.556326  [ 7600/50000]\n",
      "loss: 1.493253  [ 8000/50000]\n",
      "loss: 2.471182  [ 8400/50000]\n",
      "loss: 2.332812  [ 8800/50000]\n",
      "loss: 1.419941  [ 9200/50000]\n",
      "loss: 1.765575  [ 9600/50000]\n",
      "loss: 1.432527  [10000/50000]\n",
      "loss: 0.777598  [10400/50000]\n",
      "loss: 1.670730  [10800/50000]\n",
      "loss: 2.371309  [11200/50000]\n",
      "loss: 2.380750  [11600/50000]\n",
      "loss: 2.200430  [12000/50000]\n",
      "loss: 1.301094  [12400/50000]\n",
      "loss: 1.359703  [12800/50000]\n",
      "loss: 1.874874  [13200/50000]\n",
      "loss: 1.950120  [13600/50000]\n",
      "loss: 2.295929  [14000/50000]\n",
      "loss: 1.590394  [14400/50000]\n",
      "loss: 2.080227  [14800/50000]\n",
      "loss: 1.629140  [15200/50000]\n",
      "loss: 2.442460  [15600/50000]\n",
      "loss: 2.213140  [16000/50000]\n",
      "loss: 1.883366  [16400/50000]\n",
      "loss: 1.303967  [16800/50000]\n",
      "loss: 2.079392  [17200/50000]\n",
      "loss: 1.245180  [17600/50000]\n",
      "loss: 1.645591  [18000/50000]\n",
      "loss: 1.407303  [18400/50000]\n",
      "loss: 0.938783  [18800/50000]\n",
      "loss: 1.065909  [19200/50000]\n",
      "loss: 1.272959  [19600/50000]\n",
      "loss: 2.107970  [20000/50000]\n",
      "loss: 1.517143  [20400/50000]\n",
      "loss: 2.041228  [20800/50000]\n",
      "loss: 1.813156  [21200/50000]\n",
      "loss: 1.002742  [21600/50000]\n",
      "loss: 1.079951  [22000/50000]\n",
      "loss: 1.523432  [22400/50000]\n",
      "loss: 1.994842  [22800/50000]\n",
      "loss: 2.413687  [23200/50000]\n",
      "loss: 0.771927  [23600/50000]\n",
      "loss: 0.863029  [24000/50000]\n",
      "loss: 0.973176  [24400/50000]\n",
      "loss: 0.996050  [24800/50000]\n",
      "loss: 1.288877  [25200/50000]\n",
      "loss: 1.723096  [25600/50000]\n",
      "loss: 1.344717  [26000/50000]\n",
      "loss: 2.394537  [26400/50000]\n",
      "loss: 1.720514  [26800/50000]\n",
      "loss: 1.734267  [27200/50000]\n",
      "loss: 2.062898  [27600/50000]\n",
      "loss: 1.937474  [28000/50000]\n",
      "loss: 2.686586  [28400/50000]\n",
      "loss: 2.038309  [28800/50000]\n",
      "loss: 1.704894  [29200/50000]\n",
      "loss: 1.398187  [29600/50000]\n",
      "loss: 1.739257  [30000/50000]\n",
      "loss: 1.853697  [30400/50000]\n",
      "loss: 1.306609  [30800/50000]\n",
      "loss: 1.288130  [31200/50000]\n",
      "loss: 2.148930  [31600/50000]\n",
      "loss: 0.906573  [32000/50000]\n",
      "loss: 1.030955  [32400/50000]\n",
      "loss: 1.943738  [32800/50000]\n",
      "loss: 1.647006  [33200/50000]\n",
      "loss: 1.615268  [33600/50000]\n",
      "loss: 1.741143  [34000/50000]\n",
      "loss: 1.176036  [34400/50000]\n",
      "loss: 1.546020  [34800/50000]\n",
      "loss: 1.615672  [35200/50000]\n",
      "loss: 1.315846  [35600/50000]\n",
      "loss: 1.386830  [36000/50000]\n",
      "loss: 1.789611  [36400/50000]\n",
      "loss: 0.933188  [36800/50000]\n",
      "loss: 0.807665  [37200/50000]\n",
      "loss: 0.916000  [37600/50000]\n",
      "loss: 1.134017  [38000/50000]\n",
      "loss: 1.497413  [38400/50000]\n",
      "loss: 1.134673  [38800/50000]\n",
      "loss: 1.705807  [39200/50000]\n",
      "loss: 1.001252  [39600/50000]\n",
      "loss: 0.583800  [40000/50000]\n",
      "loss: 1.763169  [40400/50000]\n",
      "loss: 1.714017  [40800/50000]\n",
      "loss: 0.740992  [41200/50000]\n",
      "loss: 1.399376  [41600/50000]\n",
      "loss: 1.544624  [42000/50000]\n",
      "loss: 1.268749  [42400/50000]\n",
      "loss: 1.667042  [42800/50000]\n",
      "loss: 1.477301  [43200/50000]\n",
      "loss: 0.927054  [43600/50000]\n",
      "loss: 1.623962  [44000/50000]\n",
      "loss: 0.994335  [44400/50000]\n",
      "loss: 1.989552  [44800/50000]\n",
      "loss: 1.366542  [45200/50000]\n",
      "loss: 1.003333  [45600/50000]\n",
      "loss: 1.086616  [46000/50000]\n",
      "loss: 2.370813  [46400/50000]\n",
      "loss: 1.986438  [46800/50000]\n",
      "loss: 2.048186  [47200/50000]\n",
      "loss: 1.076773  [47600/50000]\n",
      "loss: 2.482544  [48000/50000]\n",
      "loss: 1.130061  [48400/50000]\n",
      "loss: 1.997416  [48800/50000]\n",
      "loss: 0.951884  [49200/50000]\n",
      "loss: 1.375225  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 0.362123 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.248279  [    0/50000]\n",
      "loss: 1.988296  [  400/50000]\n",
      "loss: 1.780607  [  800/50000]\n",
      "loss: 2.291517  [ 1200/50000]\n",
      "loss: 1.058885  [ 1600/50000]\n",
      "loss: 1.172479  [ 2000/50000]\n",
      "loss: 1.056564  [ 2400/50000]\n",
      "loss: 1.201798  [ 2800/50000]\n",
      "loss: 2.121032  [ 3200/50000]\n",
      "loss: 0.994784  [ 3600/50000]\n",
      "loss: 0.761411  [ 4000/50000]\n",
      "loss: 1.193295  [ 4400/50000]\n",
      "loss: 1.935421  [ 4800/50000]\n",
      "loss: 1.141772  [ 5200/50000]\n",
      "loss: 0.860309  [ 5600/50000]\n",
      "loss: 1.306761  [ 6000/50000]\n",
      "loss: 1.502311  [ 6400/50000]\n",
      "loss: 1.602316  [ 6800/50000]\n",
      "loss: 1.281380  [ 7200/50000]\n",
      "loss: 1.643453  [ 7600/50000]\n",
      "loss: 1.557821  [ 8000/50000]\n",
      "loss: 2.098658  [ 8400/50000]\n",
      "loss: 2.173072  [ 8800/50000]\n",
      "loss: 1.529527  [ 9200/50000]\n",
      "loss: 1.962103  [ 9600/50000]\n",
      "loss: 1.278361  [10000/50000]\n",
      "loss: 0.699732  [10400/50000]\n",
      "loss: 1.675465  [10800/50000]\n",
      "loss: 2.150224  [11200/50000]\n",
      "loss: 2.447267  [11600/50000]\n",
      "loss: 2.040823  [12000/50000]\n",
      "loss: 1.021327  [12400/50000]\n",
      "loss: 1.273462  [12800/50000]\n",
      "loss: 1.908985  [13200/50000]\n",
      "loss: 1.756266  [13600/50000]\n",
      "loss: 2.316581  [14000/50000]\n",
      "loss: 1.538223  [14400/50000]\n",
      "loss: 2.087587  [14800/50000]\n",
      "loss: 1.627586  [15200/50000]\n",
      "loss: 2.446078  [15600/50000]\n",
      "loss: 2.162428  [16000/50000]\n",
      "loss: 1.663036  [16400/50000]\n",
      "loss: 1.160515  [16800/50000]\n",
      "loss: 1.978504  [17200/50000]\n",
      "loss: 1.157374  [17600/50000]\n",
      "loss: 1.795778  [18000/50000]\n",
      "loss: 1.151594  [18400/50000]\n",
      "loss: 0.861519  [18800/50000]\n",
      "loss: 0.971690  [19200/50000]\n",
      "loss: 1.183869  [19600/50000]\n",
      "loss: 2.073730  [20000/50000]\n",
      "loss: 1.346612  [20400/50000]\n",
      "loss: 2.297857  [20800/50000]\n",
      "loss: 1.839931  [21200/50000]\n",
      "loss: 0.813157  [21600/50000]\n",
      "loss: 0.958352  [22000/50000]\n",
      "loss: 1.242770  [22400/50000]\n",
      "loss: 2.095441  [22800/50000]\n",
      "loss: 2.288713  [23200/50000]\n",
      "loss: 0.717364  [23600/50000]\n",
      "loss: 0.672159  [24000/50000]\n",
      "loss: 0.744445  [24400/50000]\n",
      "loss: 0.956327  [24800/50000]\n",
      "loss: 1.222860  [25200/50000]\n",
      "loss: 1.663795  [25600/50000]\n",
      "loss: 1.242570  [26000/50000]\n",
      "loss: 2.078362  [26400/50000]\n",
      "loss: 1.793263  [26800/50000]\n",
      "loss: 1.667593  [27200/50000]\n",
      "loss: 1.967435  [27600/50000]\n",
      "loss: 2.069757  [28000/50000]\n",
      "loss: 2.567629  [28400/50000]\n",
      "loss: 2.062375  [28800/50000]\n",
      "loss: 1.767112  [29200/50000]\n",
      "loss: 1.325128  [29600/50000]\n",
      "loss: 1.973493  [30000/50000]\n",
      "loss: 1.758945  [30400/50000]\n",
      "loss: 1.220890  [30800/50000]\n",
      "loss: 1.538268  [31200/50000]\n",
      "loss: 2.011734  [31600/50000]\n",
      "loss: 0.765282  [32000/50000]\n",
      "loss: 0.942072  [32400/50000]\n",
      "loss: 1.928099  [32800/50000]\n",
      "loss: 1.609165  [33200/50000]\n",
      "loss: 1.553738  [33600/50000]\n",
      "loss: 1.741833  [34000/50000]\n",
      "loss: 1.193656  [34400/50000]\n",
      "loss: 1.397395  [34800/50000]\n",
      "loss: 1.595027  [35200/50000]\n",
      "loss: 1.168224  [35600/50000]\n",
      "loss: 1.471158  [36000/50000]\n",
      "loss: 1.807142  [36400/50000]\n",
      "loss: 0.809698  [36800/50000]\n",
      "loss: 0.775065  [37200/50000]\n",
      "loss: 0.813016  [37600/50000]\n",
      "loss: 1.060658  [38000/50000]\n",
      "loss: 1.418850  [38400/50000]\n",
      "loss: 0.892701  [38800/50000]\n",
      "loss: 1.663918  [39200/50000]\n",
      "loss: 1.046249  [39600/50000]\n",
      "loss: 0.543422  [40000/50000]\n",
      "loss: 1.755387  [40400/50000]\n",
      "loss: 1.893089  [40800/50000]\n",
      "loss: 0.620949  [41200/50000]\n",
      "loss: 1.149136  [41600/50000]\n",
      "loss: 1.304564  [42000/50000]\n",
      "loss: 1.203991  [42400/50000]\n",
      "loss: 1.612957  [42800/50000]\n",
      "loss: 1.539678  [43200/50000]\n",
      "loss: 0.641664  [43600/50000]\n",
      "loss: 1.570779  [44000/50000]\n",
      "loss: 0.920562  [44400/50000]\n",
      "loss: 1.908629  [44800/50000]\n",
      "loss: 1.269202  [45200/50000]\n",
      "loss: 0.960061  [45600/50000]\n",
      "loss: 0.962875  [46000/50000]\n",
      "loss: 2.288950  [46400/50000]\n",
      "loss: 1.944209  [46800/50000]\n",
      "loss: 2.043117  [47200/50000]\n",
      "loss: 0.952909  [47600/50000]\n",
      "loss: 2.589392  [48000/50000]\n",
      "loss: 0.934304  [48400/50000]\n",
      "loss: 1.872981  [48800/50000]\n",
      "loss: 0.913238  [49200/50000]\n",
      "loss: 1.394300  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.6%, Avg loss: 0.346725 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.133114  [    0/50000]\n",
      "loss: 1.835478  [  400/50000]\n",
      "loss: 1.755086  [  800/50000]\n",
      "loss: 2.321777  [ 1200/50000]\n",
      "loss: 1.040987  [ 1600/50000]\n",
      "loss: 1.188518  [ 2000/50000]\n",
      "loss: 1.107179  [ 2400/50000]\n",
      "loss: 1.063589  [ 2800/50000]\n",
      "loss: 1.818079  [ 3200/50000]\n",
      "loss: 0.889592  [ 3600/50000]\n",
      "loss: 0.628887  [ 4000/50000]\n",
      "loss: 1.196069  [ 4400/50000]\n",
      "loss: 1.697942  [ 4800/50000]\n",
      "loss: 1.118126  [ 5200/50000]\n",
      "loss: 0.839927  [ 5600/50000]\n",
      "loss: 1.239627  [ 6000/50000]\n",
      "loss: 1.423954  [ 6400/50000]\n",
      "loss: 1.379342  [ 6800/50000]\n",
      "loss: 1.186348  [ 7200/50000]\n",
      "loss: 1.573338  [ 7600/50000]\n",
      "loss: 1.417912  [ 8000/50000]\n",
      "loss: 1.705848  [ 8400/50000]\n",
      "loss: 2.060431  [ 8800/50000]\n",
      "loss: 1.500885  [ 9200/50000]\n",
      "loss: 1.991715  [ 9600/50000]\n",
      "loss: 1.196159  [10000/50000]\n",
      "loss: 0.707416  [10400/50000]\n",
      "loss: 1.679787  [10800/50000]\n",
      "loss: 1.939720  [11200/50000]\n",
      "loss: 2.553974  [11600/50000]\n",
      "loss: 1.825369  [12000/50000]\n",
      "loss: 0.690676  [12400/50000]\n",
      "loss: 1.225954  [12800/50000]\n",
      "loss: 1.959701  [13200/50000]\n",
      "loss: 1.661126  [13600/50000]\n",
      "loss: 2.297588  [14000/50000]\n",
      "loss: 1.490253  [14400/50000]\n",
      "loss: 1.999385  [14800/50000]\n",
      "loss: 1.619907  [15200/50000]\n",
      "loss: 2.409544  [15600/50000]\n",
      "loss: 1.946050  [16000/50000]\n",
      "loss: 1.456465  [16400/50000]\n",
      "loss: 1.145450  [16800/50000]\n",
      "loss: 1.933933  [17200/50000]\n",
      "loss: 0.980470  [17600/50000]\n",
      "loss: 1.789913  [18000/50000]\n",
      "loss: 0.942608  [18400/50000]\n",
      "loss: 0.681043  [18800/50000]\n",
      "loss: 0.862267  [19200/50000]\n",
      "loss: 1.122112  [19600/50000]\n",
      "loss: 2.114240  [20000/50000]\n",
      "loss: 1.359236  [20400/50000]\n",
      "loss: 2.528948  [20800/50000]\n",
      "loss: 1.831639  [21200/50000]\n",
      "loss: 0.673458  [21600/50000]\n",
      "loss: 0.854405  [22000/50000]\n",
      "loss: 0.984351  [22400/50000]\n",
      "loss: 2.075135  [22800/50000]\n",
      "loss: 2.125222  [23200/50000]\n",
      "loss: 0.571994  [23600/50000]\n",
      "loss: 0.557979  [24000/50000]\n",
      "loss: 0.616970  [24400/50000]\n",
      "loss: 0.926854  [24800/50000]\n",
      "loss: 1.234169  [25200/50000]\n",
      "loss: 1.568296  [25600/50000]\n",
      "loss: 1.101698  [26000/50000]\n",
      "loss: 1.851112  [26400/50000]\n",
      "loss: 1.773190  [26800/50000]\n",
      "loss: 1.665535  [27200/50000]\n",
      "loss: 1.815722  [27600/50000]\n",
      "loss: 2.036558  [28000/50000]\n",
      "loss: 2.456859  [28400/50000]\n",
      "loss: 1.947297  [28800/50000]\n",
      "loss: 1.730397  [29200/50000]\n",
      "loss: 1.193785  [29600/50000]\n",
      "loss: 2.104101  [30000/50000]\n",
      "loss: 1.613476  [30400/50000]\n",
      "loss: 1.209979  [30800/50000]\n",
      "loss: 1.763293  [31200/50000]\n",
      "loss: 1.859002  [31600/50000]\n",
      "loss: 0.651762  [32000/50000]\n",
      "loss: 0.835782  [32400/50000]\n",
      "loss: 1.952867  [32800/50000]\n",
      "loss: 1.589862  [33200/50000]\n",
      "loss: 1.440732  [33600/50000]\n",
      "loss: 1.822439  [34000/50000]\n",
      "loss: 1.156963  [34400/50000]\n",
      "loss: 1.220224  [34800/50000]\n",
      "loss: 1.587356  [35200/50000]\n",
      "loss: 1.072196  [35600/50000]\n",
      "loss: 1.527345  [36000/50000]\n",
      "loss: 1.790247  [36400/50000]\n",
      "loss: 0.667101  [36800/50000]\n",
      "loss: 0.774287  [37200/50000]\n",
      "loss: 0.768572  [37600/50000]\n",
      "loss: 1.053921  [38000/50000]\n",
      "loss: 1.350028  [38400/50000]\n",
      "loss: 0.649776  [38800/50000]\n",
      "loss: 1.506681  [39200/50000]\n",
      "loss: 1.064441  [39600/50000]\n",
      "loss: 0.460521  [40000/50000]\n",
      "loss: 1.787285  [40400/50000]\n",
      "loss: 1.998133  [40800/50000]\n",
      "loss: 0.543365  [41200/50000]\n",
      "loss: 1.026370  [41600/50000]\n",
      "loss: 1.119274  [42000/50000]\n",
      "loss: 1.207246  [42400/50000]\n",
      "loss: 1.655923  [42800/50000]\n",
      "loss: 1.581636  [43200/50000]\n",
      "loss: 0.509922  [43600/50000]\n",
      "loss: 1.529158  [44000/50000]\n",
      "loss: 0.818498  [44400/50000]\n",
      "loss: 1.878681  [44800/50000]\n",
      "loss: 1.203430  [45200/50000]\n",
      "loss: 0.937486  [45600/50000]\n",
      "loss: 0.861044  [46000/50000]\n",
      "loss: 2.330023  [46400/50000]\n",
      "loss: 1.877419  [46800/50000]\n",
      "loss: 1.979802  [47200/50000]\n",
      "loss: 0.908300  [47600/50000]\n",
      "loss: 2.460766  [48000/50000]\n",
      "loss: 0.821376  [48400/50000]\n",
      "loss: 1.654765  [48800/50000]\n",
      "loss: 0.893173  [49200/50000]\n",
      "loss: 1.368305  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.334026 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.061997  [    0/50000]\n",
      "loss: 1.795535  [  400/50000]\n",
      "loss: 1.614779  [  800/50000]\n",
      "loss: 2.265049  [ 1200/50000]\n",
      "loss: 0.965537  [ 1600/50000]\n",
      "loss: 1.237831  [ 2000/50000]\n",
      "loss: 1.127533  [ 2400/50000]\n",
      "loss: 0.974891  [ 2800/50000]\n",
      "loss: 1.563261  [ 3200/50000]\n",
      "loss: 0.817280  [ 3600/50000]\n",
      "loss: 0.583837  [ 4000/50000]\n",
      "loss: 1.218747  [ 4400/50000]\n",
      "loss: 1.587361  [ 4800/50000]\n",
      "loss: 1.080056  [ 5200/50000]\n",
      "loss: 0.850903  [ 5600/50000]\n",
      "loss: 1.120901  [ 6000/50000]\n",
      "loss: 1.349584  [ 6400/50000]\n",
      "loss: 1.270840  [ 6800/50000]\n",
      "loss: 1.015646  [ 7200/50000]\n",
      "loss: 1.474647  [ 7600/50000]\n",
      "loss: 1.334795  [ 8000/50000]\n",
      "loss: 1.290247  [ 8400/50000]\n",
      "loss: 2.052396  [ 8800/50000]\n",
      "loss: 1.472823  [ 9200/50000]\n",
      "loss: 1.956807  [ 9600/50000]\n",
      "loss: 1.072894  [10000/50000]\n",
      "loss: 0.673370  [10400/50000]\n",
      "loss: 1.719719  [10800/50000]\n",
      "loss: 1.809028  [11200/50000]\n",
      "loss: 2.581405  [11600/50000]\n",
      "loss: 1.582726  [12000/50000]\n",
      "loss: 0.481776  [12400/50000]\n",
      "loss: 1.170320  [12800/50000]\n",
      "loss: 1.921631  [13200/50000]\n",
      "loss: 1.542077  [13600/50000]\n",
      "loss: 2.249985  [14000/50000]\n",
      "loss: 1.454630  [14400/50000]\n",
      "loss: 1.875511  [14800/50000]\n",
      "loss: 1.646814  [15200/50000]\n",
      "loss: 2.416354  [15600/50000]\n",
      "loss: 1.654212  [16000/50000]\n",
      "loss: 1.293501  [16400/50000]\n",
      "loss: 1.198137  [16800/50000]\n",
      "loss: 1.910517  [17200/50000]\n",
      "loss: 0.767379  [17600/50000]\n",
      "loss: 1.670915  [18000/50000]\n",
      "loss: 0.811836  [18400/50000]\n",
      "loss: 0.607686  [18800/50000]\n",
      "loss: 0.735690  [19200/50000]\n",
      "loss: 1.063212  [19600/50000]\n",
      "loss: 2.215418  [20000/50000]\n",
      "loss: 1.347951  [20400/50000]\n",
      "loss: 2.595654  [20800/50000]\n",
      "loss: 1.793200  [21200/50000]\n",
      "loss: 0.584281  [21600/50000]\n",
      "loss: 0.790963  [22000/50000]\n",
      "loss: 0.770676  [22400/50000]\n",
      "loss: 1.970367  [22800/50000]\n",
      "loss: 1.916889  [23200/50000]\n",
      "loss: 0.415234  [23600/50000]\n",
      "loss: 0.542547  [24000/50000]\n",
      "loss: 0.520637  [24400/50000]\n",
      "loss: 0.867609  [24800/50000]\n",
      "loss: 1.143477  [25200/50000]\n",
      "loss: 1.589474  [25600/50000]\n",
      "loss: 0.964032  [26000/50000]\n",
      "loss: 1.666919  [26400/50000]\n",
      "loss: 1.725403  [26800/50000]\n",
      "loss: 1.711371  [27200/50000]\n",
      "loss: 1.783996  [27600/50000]\n",
      "loss: 2.024493  [28000/50000]\n",
      "loss: 2.404759  [28400/50000]\n",
      "loss: 1.725499  [28800/50000]\n",
      "loss: 1.668808  [29200/50000]\n",
      "loss: 1.010620  [29600/50000]\n",
      "loss: 2.250488  [30000/50000]\n",
      "loss: 1.501224  [30400/50000]\n",
      "loss: 1.190702  [30800/50000]\n",
      "loss: 1.943732  [31200/50000]\n",
      "loss: 1.733642  [31600/50000]\n",
      "loss: 0.572804  [32000/50000]\n",
      "loss: 0.756554  [32400/50000]\n",
      "loss: 1.851149  [32800/50000]\n",
      "loss: 1.543885  [33200/50000]\n",
      "loss: 1.248952  [33600/50000]\n",
      "loss: 1.894193  [34000/50000]\n",
      "loss: 1.150246  [34400/50000]\n",
      "loss: 0.999977  [34800/50000]\n",
      "loss: 1.644012  [35200/50000]\n",
      "loss: 0.971358  [35600/50000]\n",
      "loss: 1.545755  [36000/50000]\n",
      "loss: 1.851571  [36400/50000]\n",
      "loss: 0.552284  [36800/50000]\n",
      "loss: 0.743820  [37200/50000]\n",
      "loss: 0.703267  [37600/50000]\n",
      "loss: 1.056513  [38000/50000]\n",
      "loss: 1.270767  [38400/50000]\n",
      "loss: 0.466646  [38800/50000]\n",
      "loss: 1.371042  [39200/50000]\n",
      "loss: 1.007508  [39600/50000]\n",
      "loss: 0.424550  [40000/50000]\n",
      "loss: 1.788527  [40400/50000]\n",
      "loss: 1.991382  [40800/50000]\n",
      "loss: 0.465632  [41200/50000]\n",
      "loss: 0.948949  [41600/50000]\n",
      "loss: 1.054060  [42000/50000]\n",
      "loss: 1.165952  [42400/50000]\n",
      "loss: 1.652033  [42800/50000]\n",
      "loss: 1.604644  [43200/50000]\n",
      "loss: 0.465284  [43600/50000]\n",
      "loss: 1.538328  [44000/50000]\n",
      "loss: 0.703589  [44400/50000]\n",
      "loss: 1.855509  [44800/50000]\n",
      "loss: 1.172474  [45200/50000]\n",
      "loss: 0.897206  [45600/50000]\n",
      "loss: 0.830289  [46000/50000]\n",
      "loss: 2.379910  [46400/50000]\n",
      "loss: 1.735455  [46800/50000]\n",
      "loss: 1.916976  [47200/50000]\n",
      "loss: 0.842800  [47600/50000]\n",
      "loss: 2.311915  [48000/50000]\n",
      "loss: 0.733218  [48400/50000]\n",
      "loss: 1.482965  [48800/50000]\n",
      "loss: 0.884399  [49200/50000]\n",
      "loss: 1.387692  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 0.322635 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.039304  [    0/50000]\n",
      "loss: 1.804566  [  400/50000]\n",
      "loss: 1.444093  [  800/50000]\n",
      "loss: 2.143771  [ 1200/50000]\n",
      "loss: 0.925332  [ 1600/50000]\n",
      "loss: 1.097723  [ 2000/50000]\n",
      "loss: 1.073452  [ 2400/50000]\n",
      "loss: 0.900781  [ 2800/50000]\n",
      "loss: 1.304511  [ 3200/50000]\n",
      "loss: 0.771763  [ 3600/50000]\n",
      "loss: 0.578523  [ 4000/50000]\n",
      "loss: 1.267461  [ 4400/50000]\n",
      "loss: 1.621919  [ 4800/50000]\n",
      "loss: 1.020894  [ 5200/50000]\n",
      "loss: 0.875505  [ 5600/50000]\n",
      "loss: 1.056787  [ 6000/50000]\n",
      "loss: 1.298879  [ 6400/50000]\n",
      "loss: 1.221513  [ 6800/50000]\n",
      "loss: 0.906279  [ 7200/50000]\n",
      "loss: 1.390429  [ 7600/50000]\n",
      "loss: 1.272570  [ 8000/50000]\n",
      "loss: 1.027768  [ 8400/50000]\n",
      "loss: 1.991915  [ 8800/50000]\n",
      "loss: 1.450007  [ 9200/50000]\n",
      "loss: 1.829356  [ 9600/50000]\n",
      "loss: 0.870832  [10000/50000]\n",
      "loss: 0.637491  [10400/50000]\n",
      "loss: 1.768178  [10800/50000]\n",
      "loss: 1.697083  [11200/50000]\n",
      "loss: 2.614010  [11600/50000]\n",
      "loss: 1.477925  [12000/50000]\n",
      "loss: 0.339981  [12400/50000]\n",
      "loss: 1.130597  [12800/50000]\n",
      "loss: 1.820090  [13200/50000]\n",
      "loss: 1.491210  [13600/50000]\n",
      "loss: 2.227741  [14000/50000]\n",
      "loss: 1.431369  [14400/50000]\n",
      "loss: 1.744971  [14800/50000]\n",
      "loss: 1.658171  [15200/50000]\n",
      "loss: 2.326276  [15600/50000]\n",
      "loss: 1.533210  [16000/50000]\n",
      "loss: 1.217665  [16400/50000]\n",
      "loss: 1.237502  [16800/50000]\n",
      "loss: 1.784404  [17200/50000]\n",
      "loss: 0.606582  [17600/50000]\n",
      "loss: 1.578911  [18000/50000]\n",
      "loss: 0.726114  [18400/50000]\n",
      "loss: 0.633026  [18800/50000]\n",
      "loss: 0.644756  [19200/50000]\n",
      "loss: 1.087356  [19600/50000]\n",
      "loss: 2.248302  [20000/50000]\n",
      "loss: 1.274950  [20400/50000]\n",
      "loss: 2.620266  [20800/50000]\n",
      "loss: 1.666124  [21200/50000]\n",
      "loss: 0.525177  [21600/50000]\n",
      "loss: 0.762617  [22000/50000]\n",
      "loss: 0.624122  [22400/50000]\n",
      "loss: 1.860075  [22800/50000]\n",
      "loss: 1.693667  [23200/50000]\n",
      "loss: 0.311921  [23600/50000]\n",
      "loss: 0.548799  [24000/50000]\n",
      "loss: 0.466537  [24400/50000]\n",
      "loss: 0.835026  [24800/50000]\n",
      "loss: 1.115792  [25200/50000]\n",
      "loss: 1.559512  [25600/50000]\n",
      "loss: 0.834972  [26000/50000]\n",
      "loss: 1.543428  [26400/50000]\n",
      "loss: 1.632542  [26800/50000]\n",
      "loss: 1.708325  [27200/50000]\n",
      "loss: 1.743876  [27600/50000]\n",
      "loss: 1.956182  [28000/50000]\n",
      "loss: 2.344850  [28400/50000]\n",
      "loss: 1.568445  [28800/50000]\n",
      "loss: 1.682565  [29200/50000]\n",
      "loss: 0.839339  [29600/50000]\n",
      "loss: 2.381225  [30000/50000]\n",
      "loss: 1.424961  [30400/50000]\n",
      "loss: 1.138472  [30800/50000]\n",
      "loss: 2.062185  [31200/50000]\n",
      "loss: 1.638425  [31600/50000]\n",
      "loss: 0.487757  [32000/50000]\n",
      "loss: 0.720800  [32400/50000]\n",
      "loss: 1.793368  [32800/50000]\n",
      "loss: 1.446662  [33200/50000]\n",
      "loss: 1.023617  [33600/50000]\n",
      "loss: 1.924852  [34000/50000]\n",
      "loss: 1.161319  [34400/50000]\n",
      "loss: 0.805590  [34800/50000]\n",
      "loss: 1.780308  [35200/50000]\n",
      "loss: 0.859147  [35600/50000]\n",
      "loss: 1.533650  [36000/50000]\n",
      "loss: 1.942392  [36400/50000]\n",
      "loss: 0.521539  [36800/50000]\n",
      "loss: 0.720416  [37200/50000]\n",
      "loss: 0.642202  [37600/50000]\n",
      "loss: 1.072651  [38000/50000]\n",
      "loss: 1.198975  [38400/50000]\n",
      "loss: 0.339836  [38800/50000]\n",
      "loss: 1.212070  [39200/50000]\n",
      "loss: 0.959059  [39600/50000]\n",
      "loss: 0.428215  [40000/50000]\n",
      "loss: 1.817487  [40400/50000]\n",
      "loss: 1.870668  [40800/50000]\n",
      "loss: 0.399937  [41200/50000]\n",
      "loss: 0.891458  [41600/50000]\n",
      "loss: 1.051878  [42000/50000]\n",
      "loss: 1.155637  [42400/50000]\n",
      "loss: 1.696721  [42800/50000]\n",
      "loss: 1.586166  [43200/50000]\n",
      "loss: 0.446373  [43600/50000]\n",
      "loss: 1.555978  [44000/50000]\n",
      "loss: 0.583687  [44400/50000]\n",
      "loss: 1.711868  [44800/50000]\n",
      "loss: 1.141972  [45200/50000]\n",
      "loss: 0.812116  [45600/50000]\n",
      "loss: 0.831887  [46000/50000]\n",
      "loss: 2.428944  [46400/50000]\n",
      "loss: 1.562436  [46800/50000]\n",
      "loss: 1.917914  [47200/50000]\n",
      "loss: 0.769648  [47600/50000]\n",
      "loss: 2.073848  [48000/50000]\n",
      "loss: 0.693500  [48400/50000]\n",
      "loss: 1.415555  [48800/50000]\n",
      "loss: 0.926151  [49200/50000]\n",
      "loss: 1.405956  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 0.312558 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.033934  [    0/50000]\n",
      "loss: 1.876853  [  400/50000]\n",
      "loss: 1.275936  [  800/50000]\n",
      "loss: 2.076636  [ 1200/50000]\n",
      "loss: 0.931714  [ 1600/50000]\n",
      "loss: 0.941539  [ 2000/50000]\n",
      "loss: 1.028977  [ 2400/50000]\n",
      "loss: 0.868596  [ 2800/50000]\n",
      "loss: 1.151029  [ 3200/50000]\n",
      "loss: 0.737783  [ 3600/50000]\n",
      "loss: 0.626818  [ 4000/50000]\n",
      "loss: 1.291492  [ 4400/50000]\n",
      "loss: 1.680299  [ 4800/50000]\n",
      "loss: 0.946698  [ 5200/50000]\n",
      "loss: 0.909855  [ 5600/50000]\n",
      "loss: 1.015813  [ 6000/50000]\n",
      "loss: 1.278787  [ 6400/50000]\n",
      "loss: 1.209715  [ 6800/50000]\n",
      "loss: 0.841923  [ 7200/50000]\n",
      "loss: 1.293579  [ 7600/50000]\n",
      "loss: 1.216312  [ 8000/50000]\n",
      "loss: 0.811016  [ 8400/50000]\n",
      "loss: 1.908963  [ 8800/50000]\n",
      "loss: 1.494921  [ 9200/50000]\n",
      "loss: 1.793444  [ 9600/50000]\n",
      "loss: 0.720971  [10000/50000]\n",
      "loss: 0.569692  [10400/50000]\n",
      "loss: 1.712496  [10800/50000]\n",
      "loss: 1.730556  [11200/50000]\n",
      "loss: 2.539639  [11600/50000]\n",
      "loss: 1.340292  [12000/50000]\n",
      "loss: 0.246895  [12400/50000]\n",
      "loss: 1.071737  [12800/50000]\n",
      "loss: 1.808527  [13200/50000]\n",
      "loss: 1.383441  [13600/50000]\n",
      "loss: 2.179126  [14000/50000]\n",
      "loss: 1.390246  [14400/50000]\n",
      "loss: 1.581023  [14800/50000]\n",
      "loss: 1.640287  [15200/50000]\n",
      "loss: 2.123568  [15600/50000]\n",
      "loss: 1.440125  [16000/50000]\n",
      "loss: 1.143115  [16400/50000]\n",
      "loss: 1.299271  [16800/50000]\n",
      "loss: 1.640762  [17200/50000]\n",
      "loss: 0.441427  [17600/50000]\n",
      "loss: 1.554333  [18000/50000]\n",
      "loss: 0.645903  [18400/50000]\n",
      "loss: 0.643417  [18800/50000]\n",
      "loss: 0.564488  [19200/50000]\n",
      "loss: 1.111557  [19600/50000]\n",
      "loss: 2.313654  [20000/50000]\n",
      "loss: 1.231472  [20400/50000]\n",
      "loss: 2.549626  [20800/50000]\n",
      "loss: 1.586132  [21200/50000]\n",
      "loss: 0.490500  [21600/50000]\n",
      "loss: 0.741063  [22000/50000]\n",
      "loss: 0.556633  [22400/50000]\n",
      "loss: 1.752855  [22800/50000]\n",
      "loss: 1.494334  [23200/50000]\n",
      "loss: 0.235562  [23600/50000]\n",
      "loss: 0.524230  [24000/50000]\n",
      "loss: 0.446172  [24400/50000]\n",
      "loss: 0.754216  [24800/50000]\n",
      "loss: 1.047878  [25200/50000]\n",
      "loss: 1.516248  [25600/50000]\n",
      "loss: 0.813923  [26000/50000]\n",
      "loss: 1.446506  [26400/50000]\n",
      "loss: 1.618416  [26800/50000]\n",
      "loss: 1.714780  [27200/50000]\n",
      "loss: 1.658604  [27600/50000]\n",
      "loss: 1.898211  [28000/50000]\n",
      "loss: 2.266700  [28400/50000]\n",
      "loss: 1.433979  [28800/50000]\n",
      "loss: 1.698652  [29200/50000]\n",
      "loss: 0.681811  [29600/50000]\n",
      "loss: 2.360358  [30000/50000]\n",
      "loss: 1.376780  [30400/50000]\n",
      "loss: 1.121778  [30800/50000]\n",
      "loss: 2.101791  [31200/50000]\n",
      "loss: 1.566110  [31600/50000]\n",
      "loss: 0.430163  [32000/50000]\n",
      "loss: 0.689127  [32400/50000]\n",
      "loss: 1.765169  [32800/50000]\n",
      "loss: 1.410196  [33200/50000]\n",
      "loss: 0.916129  [33600/50000]\n",
      "loss: 1.948372  [34000/50000]\n",
      "loss: 1.056458  [34400/50000]\n",
      "loss: 0.714512  [34800/50000]\n",
      "loss: 1.908731  [35200/50000]\n",
      "loss: 0.771292  [35600/50000]\n",
      "loss: 1.472343  [36000/50000]\n",
      "loss: 1.964916  [36400/50000]\n",
      "loss: 0.554884  [36800/50000]\n",
      "loss: 0.690413  [37200/50000]\n",
      "loss: 0.560769  [37600/50000]\n",
      "loss: 1.079088  [38000/50000]\n",
      "loss: 1.133728  [38400/50000]\n",
      "loss: 0.257401  [38800/50000]\n",
      "loss: 1.161776  [39200/50000]\n",
      "loss: 0.850224  [39600/50000]\n",
      "loss: 0.442053  [40000/50000]\n",
      "loss: 1.732983  [40400/50000]\n",
      "loss: 1.640471  [40800/50000]\n",
      "loss: 0.344647  [41200/50000]\n",
      "loss: 0.837269  [41600/50000]\n",
      "loss: 1.051693  [42000/50000]\n",
      "loss: 1.215202  [42400/50000]\n",
      "loss: 1.740597  [42800/50000]\n",
      "loss: 1.582823  [43200/50000]\n",
      "loss: 0.454666  [43600/50000]\n",
      "loss: 1.612880  [44000/50000]\n",
      "loss: 0.484889  [44400/50000]\n",
      "loss: 1.554187  [44800/50000]\n",
      "loss: 1.138795  [45200/50000]\n",
      "loss: 0.718000  [45600/50000]\n",
      "loss: 0.806502  [46000/50000]\n",
      "loss: 2.381184  [46400/50000]\n",
      "loss: 1.441109  [46800/50000]\n",
      "loss: 1.853343  [47200/50000]\n",
      "loss: 0.755882  [47600/50000]\n",
      "loss: 1.974305  [48000/50000]\n",
      "loss: 0.660228  [48400/50000]\n",
      "loss: 1.325042  [48800/50000]\n",
      "loss: 0.985514  [49200/50000]\n",
      "loss: 1.363871  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.303796 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.024940  [    0/50000]\n",
      "loss: 1.937385  [  400/50000]\n",
      "loss: 1.143857  [  800/50000]\n",
      "loss: 2.007471  [ 1200/50000]\n",
      "loss: 0.947798  [ 1600/50000]\n",
      "loss: 0.801518  [ 2000/50000]\n",
      "loss: 0.993118  [ 2400/50000]\n",
      "loss: 0.732907  [ 2800/50000]\n",
      "loss: 1.048140  [ 3200/50000]\n",
      "loss: 0.731009  [ 3600/50000]\n",
      "loss: 0.727858  [ 4000/50000]\n",
      "loss: 1.295946  [ 4400/50000]\n",
      "loss: 1.725707  [ 4800/50000]\n",
      "loss: 0.941666  [ 5200/50000]\n",
      "loss: 0.963483  [ 5600/50000]\n",
      "loss: 0.946943  [ 6000/50000]\n",
      "loss: 1.169376  [ 6400/50000]\n",
      "loss: 1.283627  [ 6800/50000]\n",
      "loss: 0.792933  [ 7200/50000]\n",
      "loss: 1.237562  [ 7600/50000]\n",
      "loss: 1.129673  [ 8000/50000]\n",
      "loss: 0.721203  [ 8400/50000]\n",
      "loss: 1.796106  [ 8800/50000]\n",
      "loss: 1.475265  [ 9200/50000]\n",
      "loss: 1.737211  [ 9600/50000]\n",
      "loss: 0.649271  [10000/50000]\n",
      "loss: 0.510578  [10400/50000]\n",
      "loss: 1.683198  [10800/50000]\n",
      "loss: 1.734648  [11200/50000]\n",
      "loss: 2.418648  [11600/50000]\n",
      "loss: 1.255266  [12000/50000]\n",
      "loss: 0.166132  [12400/50000]\n",
      "loss: 1.024180  [12800/50000]\n",
      "loss: 1.726287  [13200/50000]\n",
      "loss: 1.261720  [13600/50000]\n",
      "loss: 2.115171  [14000/50000]\n",
      "loss: 1.340483  [14400/50000]\n",
      "loss: 1.518836  [14800/50000]\n",
      "loss: 1.601571  [15200/50000]\n",
      "loss: 1.968833  [15600/50000]\n",
      "loss: 1.354764  [16000/50000]\n",
      "loss: 1.128455  [16400/50000]\n",
      "loss: 1.311424  [16800/50000]\n",
      "loss: 1.501766  [17200/50000]\n",
      "loss: 0.317132  [17600/50000]\n",
      "loss: 1.524512  [18000/50000]\n",
      "loss: 0.589135  [18400/50000]\n",
      "loss: 0.652613  [18800/50000]\n",
      "loss: 0.485808  [19200/50000]\n",
      "loss: 1.160694  [19600/50000]\n",
      "loss: 2.265835  [20000/50000]\n",
      "loss: 1.184187  [20400/50000]\n",
      "loss: 2.570212  [20800/50000]\n",
      "loss: 1.541601  [21200/50000]\n",
      "loss: 0.443670  [21600/50000]\n",
      "loss: 0.752631  [22000/50000]\n",
      "loss: 0.541950  [22400/50000]\n",
      "loss: 1.621439  [22800/50000]\n",
      "loss: 1.321893  [23200/50000]\n",
      "loss: 0.180030  [23600/50000]\n",
      "loss: 0.489283  [24000/50000]\n",
      "loss: 0.425462  [24400/50000]\n",
      "loss: 0.694793  [24800/50000]\n",
      "loss: 1.009383  [25200/50000]\n",
      "loss: 1.504076  [25600/50000]\n",
      "loss: 0.845554  [26000/50000]\n",
      "loss: 1.401312  [26400/50000]\n",
      "loss: 1.586714  [26800/50000]\n",
      "loss: 1.724166  [27200/50000]\n",
      "loss: 1.618718  [27600/50000]\n",
      "loss: 1.841134  [28000/50000]\n",
      "loss: 2.174576  [28400/50000]\n",
      "loss: 1.322726  [28800/50000]\n",
      "loss: 1.809692  [29200/50000]\n",
      "loss: 0.624207  [29600/50000]\n",
      "loss: 2.361043  [30000/50000]\n",
      "loss: 1.378613  [30400/50000]\n",
      "loss: 1.103420  [30800/50000]\n",
      "loss: 2.058146  [31200/50000]\n",
      "loss: 1.477299  [31600/50000]\n",
      "loss: 0.382682  [32000/50000]\n",
      "loss: 0.671783  [32400/50000]\n",
      "loss: 1.767772  [32800/50000]\n",
      "loss: 1.426411  [33200/50000]\n",
      "loss: 0.795899  [33600/50000]\n",
      "loss: 1.904786  [34000/50000]\n",
      "loss: 0.981686  [34400/50000]\n",
      "loss: 0.661838  [34800/50000]\n",
      "loss: 2.058916  [35200/50000]\n",
      "loss: 0.686972  [35600/50000]\n",
      "loss: 1.470454  [36000/50000]\n",
      "loss: 1.982021  [36400/50000]\n",
      "loss: 0.571223  [36800/50000]\n",
      "loss: 0.596419  [37200/50000]\n",
      "loss: 0.477408  [37600/50000]\n",
      "loss: 1.050542  [38000/50000]\n",
      "loss: 1.067003  [38400/50000]\n",
      "loss: 0.215267  [38800/50000]\n",
      "loss: 1.008788  [39200/50000]\n",
      "loss: 0.781916  [39600/50000]\n",
      "loss: 0.433038  [40000/50000]\n",
      "loss: 1.605361  [40400/50000]\n",
      "loss: 1.583251  [40800/50000]\n",
      "loss: 0.299064  [41200/50000]\n",
      "loss: 0.766048  [41600/50000]\n",
      "loss: 0.968574  [42000/50000]\n",
      "loss: 1.292493  [42400/50000]\n",
      "loss: 1.788326  [42800/50000]\n",
      "loss: 1.585773  [43200/50000]\n",
      "loss: 0.461805  [43600/50000]\n",
      "loss: 1.689106  [44000/50000]\n",
      "loss: 0.412266  [44400/50000]\n",
      "loss: 1.409793  [44800/50000]\n",
      "loss: 1.072534  [45200/50000]\n",
      "loss: 0.664970  [45600/50000]\n",
      "loss: 0.768087  [46000/50000]\n",
      "loss: 2.471357  [46400/50000]\n",
      "loss: 1.348707  [46800/50000]\n",
      "loss: 1.780191  [47200/50000]\n",
      "loss: 0.705924  [47600/50000]\n",
      "loss: 1.829836  [48000/50000]\n",
      "loss: 0.593654  [48400/50000]\n",
      "loss: 1.242273  [48800/50000]\n",
      "loss: 1.042043  [49200/50000]\n",
      "loss: 1.336697  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 0.297004 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.943296  [    0/50000]\n",
      "loss: 1.991087  [  400/50000]\n",
      "loss: 1.054675  [  800/50000]\n",
      "loss: 2.041735  [ 1200/50000]\n",
      "loss: 0.956647  [ 1600/50000]\n",
      "loss: 0.686025  [ 2000/50000]\n",
      "loss: 0.917730  [ 2400/50000]\n",
      "loss: 0.697376  [ 2800/50000]\n",
      "loss: 0.964570  [ 3200/50000]\n",
      "loss: 0.716580  [ 3600/50000]\n",
      "loss: 0.732264  [ 4000/50000]\n",
      "loss: 1.250029  [ 4400/50000]\n",
      "loss: 1.720088  [ 4800/50000]\n",
      "loss: 0.912614  [ 5200/50000]\n",
      "loss: 1.039039  [ 5600/50000]\n",
      "loss: 0.890698  [ 6000/50000]\n",
      "loss: 1.085862  [ 6400/50000]\n",
      "loss: 1.285154  [ 6800/50000]\n",
      "loss: 0.785687  [ 7200/50000]\n",
      "loss: 1.134350  [ 7600/50000]\n",
      "loss: 1.069751  [ 8000/50000]\n",
      "loss: 0.668166  [ 8400/50000]\n",
      "loss: 1.717891  [ 8800/50000]\n",
      "loss: 1.541953  [ 9200/50000]\n",
      "loss: 1.712492  [ 9600/50000]\n",
      "loss: 0.571400  [10000/50000]\n",
      "loss: 0.455381  [10400/50000]\n",
      "loss: 1.716011  [10800/50000]\n",
      "loss: 1.751727  [11200/50000]\n",
      "loss: 2.333140  [11600/50000]\n",
      "loss: 1.200122  [12000/50000]\n",
      "loss: 0.113331  [12400/50000]\n",
      "loss: 1.010391  [12800/50000]\n",
      "loss: 1.724905  [13200/50000]\n",
      "loss: 1.163802  [13600/50000]\n",
      "loss: 2.055773  [14000/50000]\n",
      "loss: 1.290655  [14400/50000]\n",
      "loss: 1.476537  [14800/50000]\n",
      "loss: 1.527584  [15200/50000]\n",
      "loss: 1.898938  [15600/50000]\n",
      "loss: 1.335949  [16000/50000]\n",
      "loss: 1.123332  [16400/50000]\n",
      "loss: 1.398298  [16800/50000]\n",
      "loss: 1.472641  [17200/50000]\n",
      "loss: 0.221756  [17600/50000]\n",
      "loss: 1.503800  [18000/50000]\n",
      "loss: 0.526421  [18400/50000]\n",
      "loss: 0.592945  [18800/50000]\n",
      "loss: 0.426924  [19200/50000]\n",
      "loss: 1.159183  [19600/50000]\n",
      "loss: 2.324601  [20000/50000]\n",
      "loss: 1.190283  [20400/50000]\n",
      "loss: 2.480458  [20800/50000]\n",
      "loss: 1.528327  [21200/50000]\n",
      "loss: 0.381599  [21600/50000]\n",
      "loss: 0.731695  [22000/50000]\n",
      "loss: 0.555197  [22400/50000]\n",
      "loss: 1.395583  [22800/50000]\n",
      "loss: 1.138240  [23200/50000]\n",
      "loss: 0.158287  [23600/50000]\n",
      "loss: 0.445568  [24000/50000]\n",
      "loss: 0.397781  [24400/50000]\n",
      "loss: 0.645932  [24800/50000]\n",
      "loss: 0.981053  [25200/50000]\n",
      "loss: 1.473414  [25600/50000]\n",
      "loss: 0.913113  [26000/50000]\n",
      "loss: 1.401999  [26400/50000]\n",
      "loss: 1.522362  [26800/50000]\n",
      "loss: 1.758783  [27200/50000]\n",
      "loss: 1.510704  [27600/50000]\n",
      "loss: 1.751657  [28000/50000]\n",
      "loss: 2.002835  [28400/50000]\n",
      "loss: 1.269543  [28800/50000]\n",
      "loss: 1.749691  [29200/50000]\n",
      "loss: 0.560044  [29600/50000]\n",
      "loss: 2.200283  [30000/50000]\n",
      "loss: 1.413161  [30400/50000]\n",
      "loss: 1.118951  [30800/50000]\n",
      "loss: 2.055102  [31200/50000]\n",
      "loss: 1.447872  [31600/50000]\n",
      "loss: 0.350091  [32000/50000]\n",
      "loss: 0.661977  [32400/50000]\n",
      "loss: 1.858025  [32800/50000]\n",
      "loss: 1.396174  [33200/50000]\n",
      "loss: 0.698821  [33600/50000]\n",
      "loss: 1.870677  [34000/50000]\n",
      "loss: 0.919665  [34400/50000]\n",
      "loss: 0.612390  [34800/50000]\n",
      "loss: 2.085736  [35200/50000]\n",
      "loss: 0.627432  [35600/50000]\n",
      "loss: 1.435558  [36000/50000]\n",
      "loss: 1.974369  [36400/50000]\n",
      "loss: 0.589685  [36800/50000]\n",
      "loss: 0.552500  [37200/50000]\n",
      "loss: 0.427008  [37600/50000]\n",
      "loss: 1.064509  [38000/50000]\n",
      "loss: 1.035244  [38400/50000]\n",
      "loss: 0.197999  [38800/50000]\n",
      "loss: 0.921431  [39200/50000]\n",
      "loss: 0.717109  [39600/50000]\n",
      "loss: 0.417796  [40000/50000]\n",
      "loss: 1.535161  [40400/50000]\n",
      "loss: 1.572459  [40800/50000]\n",
      "loss: 0.261142  [41200/50000]\n",
      "loss: 0.694901  [41600/50000]\n",
      "loss: 0.875161  [42000/50000]\n",
      "loss: 1.337126  [42400/50000]\n",
      "loss: 1.782094  [42800/50000]\n",
      "loss: 1.641186  [43200/50000]\n",
      "loss: 0.447396  [43600/50000]\n",
      "loss: 1.784745  [44000/50000]\n",
      "loss: 0.382702  [44400/50000]\n",
      "loss: 1.324636  [44800/50000]\n",
      "loss: 1.050838  [45200/50000]\n",
      "loss: 0.645807  [45600/50000]\n",
      "loss: 0.675387  [46000/50000]\n",
      "loss: 2.597017  [46400/50000]\n",
      "loss: 1.276393  [46800/50000]\n",
      "loss: 1.673390  [47200/50000]\n",
      "loss: 0.699519  [47600/50000]\n",
      "loss: 1.656548  [48000/50000]\n",
      "loss: 0.572159  [48400/50000]\n",
      "loss: 1.148367  [48800/50000]\n",
      "loss: 1.077621  [49200/50000]\n",
      "loss: 1.272986  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.289380 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.998881  [    0/50000]\n",
      "loss: 2.052394  [  400/50000]\n",
      "loss: 0.949691  [  800/50000]\n",
      "loss: 2.055570  [ 1200/50000]\n",
      "loss: 0.941827  [ 1600/50000]\n",
      "loss: 0.591308  [ 2000/50000]\n",
      "loss: 0.820340  [ 2400/50000]\n",
      "loss: 0.615956  [ 2800/50000]\n",
      "loss: 0.893899  [ 3200/50000]\n",
      "loss: 0.634374  [ 3600/50000]\n",
      "loss: 0.802784  [ 4000/50000]\n",
      "loss: 1.195058  [ 4400/50000]\n",
      "loss: 1.625511  [ 4800/50000]\n",
      "loss: 0.886913  [ 5200/50000]\n",
      "loss: 1.112703  [ 5600/50000]\n",
      "loss: 0.843688  [ 6000/50000]\n",
      "loss: 1.050108  [ 6400/50000]\n",
      "loss: 1.260040  [ 6800/50000]\n",
      "loss: 0.787364  [ 7200/50000]\n",
      "loss: 1.005623  [ 7600/50000]\n",
      "loss: 0.983629  [ 8000/50000]\n",
      "loss: 0.621114  [ 8400/50000]\n",
      "loss: 1.589137  [ 8800/50000]\n",
      "loss: 1.545769  [ 9200/50000]\n",
      "loss: 1.666511  [ 9600/50000]\n",
      "loss: 0.519307  [10000/50000]\n",
      "loss: 0.438081  [10400/50000]\n",
      "loss: 1.747267  [10800/50000]\n",
      "loss: 1.794676  [11200/50000]\n",
      "loss: 2.271692  [11600/50000]\n",
      "loss: 1.212412  [12000/50000]\n",
      "loss: 0.084989  [12400/50000]\n",
      "loss: 0.904464  [12800/50000]\n",
      "loss: 1.774781  [13200/50000]\n",
      "loss: 1.120608  [13600/50000]\n",
      "loss: 2.070381  [14000/50000]\n",
      "loss: 1.253204  [14400/50000]\n",
      "loss: 1.426422  [14800/50000]\n",
      "loss: 1.498261  [15200/50000]\n",
      "loss: 1.736176  [15600/50000]\n",
      "loss: 1.298047  [16000/50000]\n",
      "loss: 1.127824  [16400/50000]\n",
      "loss: 1.371982  [16800/50000]\n",
      "loss: 1.375047  [17200/50000]\n",
      "loss: 0.154160  [17600/50000]\n",
      "loss: 1.444085  [18000/50000]\n",
      "loss: 0.491621  [18400/50000]\n",
      "loss: 0.521030  [18800/50000]\n",
      "loss: 0.374249  [19200/50000]\n",
      "loss: 1.234668  [19600/50000]\n",
      "loss: 2.298723  [20000/50000]\n",
      "loss: 1.221720  [20400/50000]\n",
      "loss: 2.477653  [20800/50000]\n",
      "loss: 1.530236  [21200/50000]\n",
      "loss: 0.325518  [21600/50000]\n",
      "loss: 0.689339  [22000/50000]\n",
      "loss: 0.582394  [22400/50000]\n",
      "loss: 1.288308  [22800/50000]\n",
      "loss: 1.012291  [23200/50000]\n",
      "loss: 0.118864  [23600/50000]\n",
      "loss: 0.384647  [24000/50000]\n",
      "loss: 0.388058  [24400/50000]\n",
      "loss: 0.632497  [24800/50000]\n",
      "loss: 1.015714  [25200/50000]\n",
      "loss: 1.431449  [25600/50000]\n",
      "loss: 0.895142  [26000/50000]\n",
      "loss: 1.409419  [26400/50000]\n",
      "loss: 1.401581  [26800/50000]\n",
      "loss: 1.766537  [27200/50000]\n",
      "loss: 1.541389  [27600/50000]\n",
      "loss: 1.719404  [28000/50000]\n",
      "loss: 1.841692  [28400/50000]\n",
      "loss: 1.264028  [28800/50000]\n",
      "loss: 1.803339  [29200/50000]\n",
      "loss: 0.504476  [29600/50000]\n",
      "loss: 2.083092  [30000/50000]\n",
      "loss: 1.441094  [30400/50000]\n",
      "loss: 1.138940  [30800/50000]\n",
      "loss: 2.058393  [31200/50000]\n",
      "loss: 1.363286  [31600/50000]\n",
      "loss: 0.334689  [32000/50000]\n",
      "loss: 0.711497  [32400/50000]\n",
      "loss: 1.827584  [32800/50000]\n",
      "loss: 1.434537  [33200/50000]\n",
      "loss: 0.658220  [33600/50000]\n",
      "loss: 1.833468  [34000/50000]\n",
      "loss: 0.863703  [34400/50000]\n",
      "loss: 0.600530  [34800/50000]\n",
      "loss: 2.006784  [35200/50000]\n",
      "loss: 0.594386  [35600/50000]\n",
      "loss: 1.343467  [36000/50000]\n",
      "loss: 2.015192  [36400/50000]\n",
      "loss: 0.575560  [36800/50000]\n",
      "loss: 0.523473  [37200/50000]\n",
      "loss: 0.376834  [37600/50000]\n",
      "loss: 1.044615  [38000/50000]\n",
      "loss: 0.992080  [38400/50000]\n",
      "loss: 0.214285  [38800/50000]\n",
      "loss: 0.927445  [39200/50000]\n",
      "loss: 0.677389  [39600/50000]\n",
      "loss: 0.380528  [40000/50000]\n",
      "loss: 1.458799  [40400/50000]\n",
      "loss: 1.554744  [40800/50000]\n",
      "loss: 0.225718  [41200/50000]\n",
      "loss: 0.627307  [41600/50000]\n",
      "loss: 0.810305  [42000/50000]\n",
      "loss: 1.357905  [42400/50000]\n",
      "loss: 1.771647  [42800/50000]\n",
      "loss: 1.666794  [43200/50000]\n",
      "loss: 0.406115  [43600/50000]\n",
      "loss: 1.828825  [44000/50000]\n",
      "loss: 0.352450  [44400/50000]\n",
      "loss: 1.279950  [44800/50000]\n",
      "loss: 1.045910  [45200/50000]\n",
      "loss: 0.615853  [45600/50000]\n",
      "loss: 0.645329  [46000/50000]\n",
      "loss: 2.612567  [46400/50000]\n",
      "loss: 1.215064  [46800/50000]\n",
      "loss: 1.536958  [47200/50000]\n",
      "loss: 0.701177  [47600/50000]\n",
      "loss: 1.680543  [48000/50000]\n",
      "loss: 0.540205  [48400/50000]\n",
      "loss: 1.105990  [48800/50000]\n",
      "loss: 1.090141  [49200/50000]\n",
      "loss: 1.138075  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.285020 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.915789  [    0/50000]\n",
      "loss: 2.081879  [  400/50000]\n",
      "loss: 0.929598  [  800/50000]\n",
      "loss: 2.037089  [ 1200/50000]\n",
      "loss: 0.930189  [ 1600/50000]\n",
      "loss: 0.544890  [ 2000/50000]\n",
      "loss: 0.762598  [ 2400/50000]\n",
      "loss: 0.556151  [ 2800/50000]\n",
      "loss: 0.750431  [ 3200/50000]\n",
      "loss: 0.609530  [ 3600/50000]\n",
      "loss: 0.756403  [ 4000/50000]\n",
      "loss: 1.166284  [ 4400/50000]\n",
      "loss: 1.519388  [ 4800/50000]\n",
      "loss: 0.899990  [ 5200/50000]\n",
      "loss: 1.133172  [ 5600/50000]\n",
      "loss: 0.816158  [ 6000/50000]\n",
      "loss: 1.106015  [ 6400/50000]\n",
      "loss: 1.287751  [ 6800/50000]\n",
      "loss: 0.710606  [ 7200/50000]\n",
      "loss: 0.904518  [ 7600/50000]\n",
      "loss: 0.978736  [ 8000/50000]\n",
      "loss: 0.602669  [ 8400/50000]\n",
      "loss: 1.559324  [ 8800/50000]\n",
      "loss: 1.575186  [ 9200/50000]\n",
      "loss: 1.608912  [ 9600/50000]\n",
      "loss: 0.438399  [10000/50000]\n",
      "loss: 0.406585  [10400/50000]\n",
      "loss: 1.761556  [10800/50000]\n",
      "loss: 1.670504  [11200/50000]\n",
      "loss: 2.225656  [11600/50000]\n",
      "loss: 1.175688  [12000/50000]\n",
      "loss: 0.075717  [12400/50000]\n",
      "loss: 0.889358  [12800/50000]\n",
      "loss: 1.650948  [13200/50000]\n",
      "loss: 1.098894  [13600/50000]\n",
      "loss: 2.070896  [14000/50000]\n",
      "loss: 1.223541  [14400/50000]\n",
      "loss: 1.453119  [14800/50000]\n",
      "loss: 1.444068  [15200/50000]\n",
      "loss: 1.584744  [15600/50000]\n",
      "loss: 1.275161  [16000/50000]\n",
      "loss: 1.126074  [16400/50000]\n",
      "loss: 1.325464  [16800/50000]\n",
      "loss: 1.367663  [17200/50000]\n",
      "loss: 0.128900  [17600/50000]\n",
      "loss: 1.357104  [18000/50000]\n",
      "loss: 0.457603  [18400/50000]\n",
      "loss: 0.457944  [18800/50000]\n",
      "loss: 0.294742  [19200/50000]\n",
      "loss: 1.255327  [19600/50000]\n",
      "loss: 2.241329  [20000/50000]\n",
      "loss: 1.152868  [20400/50000]\n",
      "loss: 2.342306  [20800/50000]\n",
      "loss: 1.475695  [21200/50000]\n",
      "loss: 0.283625  [21600/50000]\n",
      "loss: 0.650452  [22000/50000]\n",
      "loss: 0.572585  [22400/50000]\n",
      "loss: 1.157122  [22800/50000]\n",
      "loss: 0.940805  [23200/50000]\n",
      "loss: 0.105393  [23600/50000]\n",
      "loss: 0.354801  [24000/50000]\n",
      "loss: 0.373450  [24400/50000]\n",
      "loss: 0.595844  [24800/50000]\n",
      "loss: 1.005667  [25200/50000]\n",
      "loss: 1.443330  [25600/50000]\n",
      "loss: 0.900506  [26000/50000]\n",
      "loss: 1.411113  [26400/50000]\n",
      "loss: 1.262398  [26800/50000]\n",
      "loss: 1.803977  [27200/50000]\n",
      "loss: 1.462424  [27600/50000]\n",
      "loss: 1.702148  [28000/50000]\n",
      "loss: 1.652122  [28400/50000]\n",
      "loss: 1.237495  [28800/50000]\n",
      "loss: 1.844029  [29200/50000]\n",
      "loss: 0.508162  [29600/50000]\n",
      "loss: 2.004341  [30000/50000]\n",
      "loss: 1.467580  [30400/50000]\n",
      "loss: 1.121346  [30800/50000]\n",
      "loss: 2.047193  [31200/50000]\n",
      "loss: 1.345212  [31600/50000]\n",
      "loss: 0.318585  [32000/50000]\n",
      "loss: 0.781161  [32400/50000]\n",
      "loss: 1.788447  [32800/50000]\n",
      "loss: 1.497527  [33200/50000]\n",
      "loss: 0.652845  [33600/50000]\n",
      "loss: 1.853265  [34000/50000]\n",
      "loss: 0.823472  [34400/50000]\n",
      "loss: 0.592053  [34800/50000]\n",
      "loss: 1.960387  [35200/50000]\n",
      "loss: 0.557848  [35600/50000]\n",
      "loss: 1.273960  [36000/50000]\n",
      "loss: 2.023164  [36400/50000]\n",
      "loss: 0.570889  [36800/50000]\n",
      "loss: 0.516559  [37200/50000]\n",
      "loss: 0.333964  [37600/50000]\n",
      "loss: 1.015708  [38000/50000]\n",
      "loss: 0.934183  [38400/50000]\n",
      "loss: 0.219312  [38800/50000]\n",
      "loss: 0.909947  [39200/50000]\n",
      "loss: 0.601432  [39600/50000]\n",
      "loss: 0.377270  [40000/50000]\n",
      "loss: 1.419020  [40400/50000]\n",
      "loss: 1.582738  [40800/50000]\n",
      "loss: 0.194266  [41200/50000]\n",
      "loss: 0.568163  [41600/50000]\n",
      "loss: 0.759410  [42000/50000]\n",
      "loss: 1.381547  [42400/50000]\n",
      "loss: 1.713562  [42800/50000]\n",
      "loss: 1.652140  [43200/50000]\n",
      "loss: 0.397790  [43600/50000]\n",
      "loss: 1.851344  [44000/50000]\n",
      "loss: 0.315705  [44400/50000]\n",
      "loss: 1.210420  [44800/50000]\n",
      "loss: 0.974529  [45200/50000]\n",
      "loss: 0.636582  [45600/50000]\n",
      "loss: 0.605987  [46000/50000]\n",
      "loss: 2.651847  [46400/50000]\n",
      "loss: 1.145615  [46800/50000]\n",
      "loss: 1.381434  [47200/50000]\n",
      "loss: 0.695626  [47600/50000]\n",
      "loss: 1.640542  [48000/50000]\n",
      "loss: 0.506913  [48400/50000]\n",
      "loss: 1.069197  [48800/50000]\n",
      "loss: 1.130263  [49200/50000]\n",
      "loss: 1.051912  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.280316 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.960286  [    0/50000]\n",
      "loss: 2.040613  [  400/50000]\n",
      "loss: 0.889046  [  800/50000]\n",
      "loss: 2.043893  [ 1200/50000]\n",
      "loss: 0.922917  [ 1600/50000]\n",
      "loss: 0.551687  [ 2000/50000]\n",
      "loss: 0.681889  [ 2400/50000]\n",
      "loss: 0.461415  [ 2800/50000]\n",
      "loss: 0.684127  [ 3200/50000]\n",
      "loss: 0.540662  [ 3600/50000]\n",
      "loss: 0.672168  [ 4000/50000]\n",
      "loss: 1.108705  [ 4400/50000]\n",
      "loss: 1.442968  [ 4800/50000]\n",
      "loss: 0.920554  [ 5200/50000]\n",
      "loss: 1.169083  [ 5600/50000]\n",
      "loss: 0.806110  [ 6000/50000]\n",
      "loss: 1.044923  [ 6400/50000]\n",
      "loss: 1.384527  [ 6800/50000]\n",
      "loss: 0.713473  [ 7200/50000]\n",
      "loss: 0.860807  [ 7600/50000]\n",
      "loss: 0.918799  [ 8000/50000]\n",
      "loss: 0.592431  [ 8400/50000]\n",
      "loss: 1.508484  [ 8800/50000]\n",
      "loss: 1.519046  [ 9200/50000]\n",
      "loss: 1.602881  [ 9600/50000]\n",
      "loss: 0.374554  [10000/50000]\n",
      "loss: 0.371509  [10400/50000]\n",
      "loss: 1.755857  [10800/50000]\n",
      "loss: 1.612679  [11200/50000]\n",
      "loss: 2.234096  [11600/50000]\n",
      "loss: 1.231673  [12000/50000]\n",
      "loss: 0.082889  [12400/50000]\n",
      "loss: 0.897830  [12800/50000]\n",
      "loss: 1.651910  [13200/50000]\n",
      "loss: 1.108551  [13600/50000]\n",
      "loss: 2.016208  [14000/50000]\n",
      "loss: 1.216834  [14400/50000]\n",
      "loss: 1.431742  [14800/50000]\n",
      "loss: 1.392366  [15200/50000]\n",
      "loss: 1.447985  [15600/50000]\n",
      "loss: 1.247503  [16000/50000]\n",
      "loss: 1.123047  [16400/50000]\n",
      "loss: 1.320707  [16800/50000]\n",
      "loss: 1.320126  [17200/50000]\n",
      "loss: 0.103568  [17600/50000]\n",
      "loss: 1.221670  [18000/50000]\n",
      "loss: 0.403625  [18400/50000]\n",
      "loss: 0.450420  [18800/50000]\n",
      "loss: 0.241989  [19200/50000]\n",
      "loss: 1.251263  [19600/50000]\n",
      "loss: 2.224795  [20000/50000]\n",
      "loss: 1.153568  [20400/50000]\n",
      "loss: 2.216454  [20800/50000]\n",
      "loss: 1.425162  [21200/50000]\n",
      "loss: 0.251621  [21600/50000]\n",
      "loss: 0.609468  [22000/50000]\n",
      "loss: 0.561498  [22400/50000]\n",
      "loss: 1.032283  [22800/50000]\n",
      "loss: 0.878257  [23200/50000]\n",
      "loss: 0.090761  [23600/50000]\n",
      "loss: 0.322306  [24000/50000]\n",
      "loss: 0.337354  [24400/50000]\n",
      "loss: 0.549251  [24800/50000]\n",
      "loss: 1.005174  [25200/50000]\n",
      "loss: 1.464650  [25600/50000]\n",
      "loss: 0.887449  [26000/50000]\n",
      "loss: 1.371344  [26400/50000]\n",
      "loss: 1.123504  [26800/50000]\n",
      "loss: 1.869435  [27200/50000]\n",
      "loss: 1.372643  [27600/50000]\n",
      "loss: 1.662099  [28000/50000]\n",
      "loss: 1.505291  [28400/50000]\n",
      "loss: 1.244822  [28800/50000]\n",
      "loss: 1.875842  [29200/50000]\n",
      "loss: 0.476097  [29600/50000]\n",
      "loss: 1.952631  [30000/50000]\n",
      "loss: 1.416395  [30400/50000]\n",
      "loss: 1.122640  [30800/50000]\n",
      "loss: 1.955293  [31200/50000]\n",
      "loss: 1.344094  [31600/50000]\n",
      "loss: 0.335509  [32000/50000]\n",
      "loss: 0.816402  [32400/50000]\n",
      "loss: 1.735690  [32800/50000]\n",
      "loss: 1.430173  [33200/50000]\n",
      "loss: 0.628320  [33600/50000]\n",
      "loss: 1.900532  [34000/50000]\n",
      "loss: 0.706944  [34400/50000]\n",
      "loss: 0.561054  [34800/50000]\n",
      "loss: 1.921629  [35200/50000]\n",
      "loss: 0.524453  [35600/50000]\n",
      "loss: 1.225686  [36000/50000]\n",
      "loss: 2.051806  [36400/50000]\n",
      "loss: 0.550741  [36800/50000]\n",
      "loss: 0.496272  [37200/50000]\n",
      "loss: 0.303814  [37600/50000]\n",
      "loss: 0.964617  [38000/50000]\n",
      "loss: 0.936072  [38400/50000]\n",
      "loss: 0.232888  [38800/50000]\n",
      "loss: 0.879558  [39200/50000]\n",
      "loss: 0.559840  [39600/50000]\n",
      "loss: 0.367653  [40000/50000]\n",
      "loss: 1.392449  [40400/50000]\n",
      "loss: 1.571818  [40800/50000]\n",
      "loss: 0.173486  [41200/50000]\n",
      "loss: 0.531655  [41600/50000]\n",
      "loss: 0.725793  [42000/50000]\n",
      "loss: 1.361105  [42400/50000]\n",
      "loss: 1.660294  [42800/50000]\n",
      "loss: 1.655483  [43200/50000]\n",
      "loss: 0.411420  [43600/50000]\n",
      "loss: 1.793498  [44000/50000]\n",
      "loss: 0.286976  [44400/50000]\n",
      "loss: 1.151132  [44800/50000]\n",
      "loss: 0.924203  [45200/50000]\n",
      "loss: 0.651819  [45600/50000]\n",
      "loss: 0.561046  [46000/50000]\n",
      "loss: 2.632270  [46400/50000]\n",
      "loss: 1.069985  [46800/50000]\n",
      "loss: 1.261092  [47200/50000]\n",
      "loss: 0.667810  [47600/50000]\n",
      "loss: 1.654571  [48000/50000]\n",
      "loss: 0.499102  [48400/50000]\n",
      "loss: 0.974128  [48800/50000]\n",
      "loss: 1.119024  [49200/50000]\n",
      "loss: 0.956681  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.277401 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.988474  [    0/50000]\n",
      "loss: 1.991520  [  400/50000]\n",
      "loss: 0.927292  [  800/50000]\n",
      "loss: 1.991298  [ 1200/50000]\n",
      "loss: 0.869722  [ 1600/50000]\n",
      "loss: 0.530404  [ 2000/50000]\n",
      "loss: 0.633359  [ 2400/50000]\n",
      "loss: 0.389830  [ 2800/50000]\n",
      "loss: 0.699219  [ 3200/50000]\n",
      "loss: 0.447495  [ 3600/50000]\n",
      "loss: 0.616087  [ 4000/50000]\n",
      "loss: 1.137379  [ 4400/50000]\n",
      "loss: 1.414788  [ 4800/50000]\n",
      "loss: 0.940669  [ 5200/50000]\n",
      "loss: 1.175719  [ 5600/50000]\n",
      "loss: 0.779647  [ 6000/50000]\n",
      "loss: 1.067645  [ 6400/50000]\n",
      "loss: 1.370207  [ 6800/50000]\n",
      "loss: 0.694153  [ 7200/50000]\n",
      "loss: 0.788724  [ 7600/50000]\n",
      "loss: 0.899752  [ 8000/50000]\n",
      "loss: 0.600820  [ 8400/50000]\n",
      "loss: 1.420756  [ 8800/50000]\n",
      "loss: 1.464939  [ 9200/50000]\n",
      "loss: 1.535921  [ 9600/50000]\n",
      "loss: 0.342213  [10000/50000]\n",
      "loss: 0.357408  [10400/50000]\n",
      "loss: 1.775832  [10800/50000]\n",
      "loss: 1.616074  [11200/50000]\n",
      "loss: 2.237588  [11600/50000]\n",
      "loss: 1.229572  [12000/50000]\n",
      "loss: 0.080066  [12400/50000]\n",
      "loss: 0.822773  [12800/50000]\n",
      "loss: 1.605730  [13200/50000]\n",
      "loss: 1.004888  [13600/50000]\n",
      "loss: 1.971874  [14000/50000]\n",
      "loss: 1.173377  [14400/50000]\n",
      "loss: 1.383614  [14800/50000]\n",
      "loss: 1.356726  [15200/50000]\n",
      "loss: 1.403549  [15600/50000]\n",
      "loss: 1.214715  [16000/50000]\n",
      "loss: 1.129349  [16400/50000]\n",
      "loss: 1.292636  [16800/50000]\n",
      "loss: 1.330327  [17200/50000]\n",
      "loss: 0.102637  [17600/50000]\n",
      "loss: 1.145640  [18000/50000]\n",
      "loss: 0.373206  [18400/50000]\n",
      "loss: 0.453821  [18800/50000]\n",
      "loss: 0.217617  [19200/50000]\n",
      "loss: 1.262902  [19600/50000]\n",
      "loss: 2.289966  [20000/50000]\n",
      "loss: 1.102058  [20400/50000]\n",
      "loss: 2.056212  [20800/50000]\n",
      "loss: 1.386260  [21200/50000]\n",
      "loss: 0.229932  [21600/50000]\n",
      "loss: 0.596573  [22000/50000]\n",
      "loss: 0.515046  [22400/50000]\n",
      "loss: 0.935722  [22800/50000]\n",
      "loss: 0.858975  [23200/50000]\n",
      "loss: 0.080100  [23600/50000]\n",
      "loss: 0.287942  [24000/50000]\n",
      "loss: 0.319571  [24400/50000]\n",
      "loss: 0.511183  [24800/50000]\n",
      "loss: 0.991095  [25200/50000]\n",
      "loss: 1.494245  [25600/50000]\n",
      "loss: 0.928074  [26000/50000]\n",
      "loss: 1.358938  [26400/50000]\n",
      "loss: 1.105838  [26800/50000]\n",
      "loss: 1.918830  [27200/50000]\n",
      "loss: 1.406822  [27600/50000]\n",
      "loss: 1.648222  [28000/50000]\n",
      "loss: 1.426403  [28400/50000]\n",
      "loss: 1.304804  [28800/50000]\n",
      "loss: 1.937856  [29200/50000]\n",
      "loss: 0.413204  [29600/50000]\n",
      "loss: 1.929680  [30000/50000]\n",
      "loss: 1.384815  [30400/50000]\n",
      "loss: 1.078425  [30800/50000]\n",
      "loss: 1.926488  [31200/50000]\n",
      "loss: 1.300709  [31600/50000]\n",
      "loss: 0.360703  [32000/50000]\n",
      "loss: 0.860052  [32400/50000]\n",
      "loss: 1.675517  [32800/50000]\n",
      "loss: 1.375632  [33200/50000]\n",
      "loss: 0.623853  [33600/50000]\n",
      "loss: 1.963005  [34000/50000]\n",
      "loss: 0.697018  [34400/50000]\n",
      "loss: 0.554635  [34800/50000]\n",
      "loss: 1.854105  [35200/50000]\n",
      "loss: 0.510441  [35600/50000]\n",
      "loss: 1.167162  [36000/50000]\n",
      "loss: 2.008637  [36400/50000]\n",
      "loss: 0.528550  [36800/50000]\n",
      "loss: 0.455284  [37200/50000]\n",
      "loss: 0.275739  [37600/50000]\n",
      "loss: 0.910509  [38000/50000]\n",
      "loss: 0.933475  [38400/50000]\n",
      "loss: 0.208438  [38800/50000]\n",
      "loss: 0.833922  [39200/50000]\n",
      "loss: 0.551890  [39600/50000]\n",
      "loss: 0.378302  [40000/50000]\n",
      "loss: 1.353754  [40400/50000]\n",
      "loss: 1.551379  [40800/50000]\n",
      "loss: 0.148206  [41200/50000]\n",
      "loss: 0.509102  [41600/50000]\n",
      "loss: 0.677161  [42000/50000]\n",
      "loss: 1.322247  [42400/50000]\n",
      "loss: 1.607710  [42800/50000]\n",
      "loss: 1.631239  [43200/50000]\n",
      "loss: 0.434725  [43600/50000]\n",
      "loss: 1.630367  [44000/50000]\n",
      "loss: 0.255551  [44400/50000]\n",
      "loss: 1.153459  [44800/50000]\n",
      "loss: 0.936495  [45200/50000]\n",
      "loss: 0.671548  [45600/50000]\n",
      "loss: 0.551122  [46000/50000]\n",
      "loss: 2.541868  [46400/50000]\n",
      "loss: 0.999107  [46800/50000]\n",
      "loss: 1.202566  [47200/50000]\n",
      "loss: 0.666262  [47600/50000]\n",
      "loss: 1.558062  [48000/50000]\n",
      "loss: 0.492846  [48400/50000]\n",
      "loss: 0.856925  [48800/50000]\n",
      "loss: 1.080850  [49200/50000]\n",
      "loss: 0.855992  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.274319 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.940809  [    0/50000]\n",
      "loss: 2.013083  [  400/50000]\n",
      "loss: 0.954690  [  800/50000]\n",
      "loss: 1.930375  [ 1200/50000]\n",
      "loss: 0.844465  [ 1600/50000]\n",
      "loss: 0.479948  [ 2000/50000]\n",
      "loss: 0.556064  [ 2400/50000]\n",
      "loss: 0.310002  [ 2800/50000]\n",
      "loss: 0.720668  [ 3200/50000]\n",
      "loss: 0.402210  [ 3600/50000]\n",
      "loss: 0.558585  [ 4000/50000]\n",
      "loss: 1.115456  [ 4400/50000]\n",
      "loss: 1.269211  [ 4800/50000]\n",
      "loss: 0.945155  [ 5200/50000]\n",
      "loss: 1.175604  [ 5600/50000]\n",
      "loss: 0.840390  [ 6000/50000]\n",
      "loss: 1.075154  [ 6400/50000]\n",
      "loss: 1.334815  [ 6800/50000]\n",
      "loss: 0.655740  [ 7200/50000]\n",
      "loss: 0.739667  [ 7600/50000]\n",
      "loss: 0.868631  [ 8000/50000]\n",
      "loss: 0.584995  [ 8400/50000]\n",
      "loss: 1.361749  [ 8800/50000]\n",
      "loss: 1.407670  [ 9200/50000]\n",
      "loss: 1.517943  [ 9600/50000]\n",
      "loss: 0.298233  [10000/50000]\n",
      "loss: 0.312042  [10400/50000]\n",
      "loss: 1.788804  [10800/50000]\n",
      "loss: 1.587499  [11200/50000]\n",
      "loss: 2.272920  [11600/50000]\n",
      "loss: 1.147647  [12000/50000]\n",
      "loss: 0.065157  [12400/50000]\n",
      "loss: 0.774998  [12800/50000]\n",
      "loss: 1.613539  [13200/50000]\n",
      "loss: 0.911883  [13600/50000]\n",
      "loss: 1.901549  [14000/50000]\n",
      "loss: 1.124381  [14400/50000]\n",
      "loss: 1.342046  [14800/50000]\n",
      "loss: 1.310476  [15200/50000]\n",
      "loss: 1.305319  [15600/50000]\n",
      "loss: 1.150001  [16000/50000]\n",
      "loss: 1.156732  [16400/50000]\n",
      "loss: 1.274065  [16800/50000]\n",
      "loss: 1.218347  [17200/50000]\n",
      "loss: 0.090352  [17600/50000]\n",
      "loss: 1.048041  [18000/50000]\n",
      "loss: 0.350121  [18400/50000]\n",
      "loss: 0.457397  [18800/50000]\n",
      "loss: 0.216887  [19200/50000]\n",
      "loss: 1.278382  [19600/50000]\n",
      "loss: 2.252901  [20000/50000]\n",
      "loss: 1.106582  [20400/50000]\n",
      "loss: 1.933372  [20800/50000]\n",
      "loss: 1.378092  [21200/50000]\n",
      "loss: 0.211237  [21600/50000]\n",
      "loss: 0.609526  [22000/50000]\n",
      "loss: 0.483663  [22400/50000]\n",
      "loss: 0.855735  [22800/50000]\n",
      "loss: 0.814576  [23200/50000]\n",
      "loss: 0.064669  [23600/50000]\n",
      "loss: 0.258475  [24000/50000]\n",
      "loss: 0.307026  [24400/50000]\n",
      "loss: 0.483006  [24800/50000]\n",
      "loss: 0.983859  [25200/50000]\n",
      "loss: 1.511866  [25600/50000]\n",
      "loss: 0.886396  [26000/50000]\n",
      "loss: 1.405530  [26400/50000]\n",
      "loss: 1.055748  [26800/50000]\n",
      "loss: 1.867598  [27200/50000]\n",
      "loss: 1.212510  [27600/50000]\n",
      "loss: 1.634964  [28000/50000]\n",
      "loss: 1.298482  [28400/50000]\n",
      "loss: 1.275965  [28800/50000]\n",
      "loss: 1.938721  [29200/50000]\n",
      "loss: 0.359266  [29600/50000]\n",
      "loss: 1.903587  [30000/50000]\n",
      "loss: 1.313532  [30400/50000]\n",
      "loss: 1.056040  [30800/50000]\n",
      "loss: 1.865400  [31200/50000]\n",
      "loss: 1.285141  [31600/50000]\n",
      "loss: 0.365694  [32000/50000]\n",
      "loss: 0.881101  [32400/50000]\n",
      "loss: 1.646858  [32800/50000]\n",
      "loss: 1.363620  [33200/50000]\n",
      "loss: 0.620623  [33600/50000]\n",
      "loss: 2.028378  [34000/50000]\n",
      "loss: 0.671389  [34400/50000]\n",
      "loss: 0.537554  [34800/50000]\n",
      "loss: 1.801739  [35200/50000]\n",
      "loss: 0.484151  [35600/50000]\n",
      "loss: 1.093913  [36000/50000]\n",
      "loss: 2.037258  [36400/50000]\n",
      "loss: 0.516654  [36800/50000]\n",
      "loss: 0.414210  [37200/50000]\n",
      "loss: 0.244866  [37600/50000]\n",
      "loss: 0.974159  [38000/50000]\n",
      "loss: 0.921981  [38400/50000]\n",
      "loss: 0.200537  [38800/50000]\n",
      "loss: 0.798324  [39200/50000]\n",
      "loss: 0.520031  [39600/50000]\n",
      "loss: 0.338577  [40000/50000]\n",
      "loss: 1.327146  [40400/50000]\n",
      "loss: 1.580904  [40800/50000]\n",
      "loss: 0.143783  [41200/50000]\n",
      "loss: 0.477662  [41600/50000]\n",
      "loss: 0.641020  [42000/50000]\n",
      "loss: 1.268086  [42400/50000]\n",
      "loss: 1.548980  [42800/50000]\n",
      "loss: 1.586054  [43200/50000]\n",
      "loss: 0.444001  [43600/50000]\n",
      "loss: 1.552888  [44000/50000]\n",
      "loss: 0.241569  [44400/50000]\n",
      "loss: 1.179553  [44800/50000]\n",
      "loss: 0.926437  [45200/50000]\n",
      "loss: 0.715436  [45600/50000]\n",
      "loss: 0.534407  [46000/50000]\n",
      "loss: 2.508688  [46400/50000]\n",
      "loss: 0.953471  [46800/50000]\n",
      "loss: 1.140912  [47200/50000]\n",
      "loss: 0.650453  [47600/50000]\n",
      "loss: 1.389700  [48000/50000]\n",
      "loss: 0.488244  [48400/50000]\n",
      "loss: 0.852299  [48800/50000]\n",
      "loss: 1.046798  [49200/50000]\n",
      "loss: 0.719392  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.270547 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.901022  [    0/50000]\n",
      "loss: 1.931410  [  400/50000]\n",
      "loss: 0.880533  [  800/50000]\n",
      "loss: 1.877690  [ 1200/50000]\n",
      "loss: 0.822193  [ 1600/50000]\n",
      "loss: 0.471265  [ 2000/50000]\n",
      "loss: 0.530704  [ 2400/50000]\n",
      "loss: 0.288087  [ 2800/50000]\n",
      "loss: 0.755594  [ 3200/50000]\n",
      "loss: 0.353558  [ 3600/50000]\n",
      "loss: 0.520098  [ 4000/50000]\n",
      "loss: 1.062835  [ 4400/50000]\n",
      "loss: 1.125625  [ 4800/50000]\n",
      "loss: 0.967433  [ 5200/50000]\n",
      "loss: 1.157623  [ 5600/50000]\n",
      "loss: 0.817686  [ 6000/50000]\n",
      "loss: 1.080780  [ 6400/50000]\n",
      "loss: 1.312798  [ 6800/50000]\n",
      "loss: 0.597553  [ 7200/50000]\n",
      "loss: 0.694514  [ 7600/50000]\n",
      "loss: 0.823058  [ 8000/50000]\n",
      "loss: 0.538576  [ 8400/50000]\n",
      "loss: 1.273883  [ 8800/50000]\n",
      "loss: 1.400115  [ 9200/50000]\n",
      "loss: 1.426156  [ 9600/50000]\n",
      "loss: 0.247595  [10000/50000]\n",
      "loss: 0.269139  [10400/50000]\n",
      "loss: 1.815614  [10800/50000]\n",
      "loss: 1.573212  [11200/50000]\n",
      "loss: 2.188481  [11600/50000]\n",
      "loss: 1.087606  [12000/50000]\n",
      "loss: 0.061999  [12400/50000]\n",
      "loss: 0.737491  [12800/50000]\n",
      "loss: 1.673037  [13200/50000]\n",
      "loss: 0.878778  [13600/50000]\n",
      "loss: 1.861374  [14000/50000]\n",
      "loss: 1.065680  [14400/50000]\n",
      "loss: 1.290761  [14800/50000]\n",
      "loss: 1.278774  [15200/50000]\n",
      "loss: 1.167505  [15600/50000]\n",
      "loss: 1.124399  [16000/50000]\n",
      "loss: 1.141644  [16400/50000]\n",
      "loss: 1.272140  [16800/50000]\n",
      "loss: 1.162726  [17200/50000]\n",
      "loss: 0.081146  [17600/50000]\n",
      "loss: 0.963046  [18000/50000]\n",
      "loss: 0.342219  [18400/50000]\n",
      "loss: 0.453355  [18800/50000]\n",
      "loss: 0.216701  [19200/50000]\n",
      "loss: 1.272370  [19600/50000]\n",
      "loss: 2.227119  [20000/50000]\n",
      "loss: 1.098815  [20400/50000]\n",
      "loss: 1.808282  [20800/50000]\n",
      "loss: 1.372131  [21200/50000]\n",
      "loss: 0.189418  [21600/50000]\n",
      "loss: 0.603558  [22000/50000]\n",
      "loss: 0.426149  [22400/50000]\n",
      "loss: 0.785573  [22800/50000]\n",
      "loss: 0.753254  [23200/50000]\n",
      "loss: 0.055592  [23600/50000]\n",
      "loss: 0.239498  [24000/50000]\n",
      "loss: 0.306645  [24400/50000]\n",
      "loss: 0.442833  [24800/50000]\n",
      "loss: 1.023023  [25200/50000]\n",
      "loss: 1.557375  [25600/50000]\n",
      "loss: 0.879108  [26000/50000]\n",
      "loss: 1.279287  [26400/50000]\n",
      "loss: 0.964660  [26800/50000]\n",
      "loss: 1.743589  [27200/50000]\n",
      "loss: 1.141628  [27600/50000]\n",
      "loss: 1.641601  [28000/50000]\n",
      "loss: 1.168968  [28400/50000]\n",
      "loss: 1.351357  [28800/50000]\n",
      "loss: 1.953201  [29200/50000]\n",
      "loss: 0.368830  [29600/50000]\n",
      "loss: 1.909239  [30000/50000]\n",
      "loss: 1.289542  [30400/50000]\n",
      "loss: 0.981550  [30800/50000]\n",
      "loss: 1.830350  [31200/50000]\n",
      "loss: 1.286049  [31600/50000]\n",
      "loss: 0.397918  [32000/50000]\n",
      "loss: 0.871430  [32400/50000]\n",
      "loss: 1.533229  [32800/50000]\n",
      "loss: 1.327995  [33200/50000]\n",
      "loss: 0.620221  [33600/50000]\n",
      "loss: 1.998616  [34000/50000]\n",
      "loss: 0.663272  [34400/50000]\n",
      "loss: 0.523427  [34800/50000]\n",
      "loss: 1.757596  [35200/50000]\n",
      "loss: 0.470864  [35600/50000]\n",
      "loss: 1.025049  [36000/50000]\n",
      "loss: 2.054358  [36400/50000]\n",
      "loss: 0.508430  [36800/50000]\n",
      "loss: 0.422251  [37200/50000]\n",
      "loss: 0.225708  [37600/50000]\n",
      "loss: 1.019935  [38000/50000]\n",
      "loss: 0.922651  [38400/50000]\n",
      "loss: 0.202750  [38800/50000]\n",
      "loss: 0.776954  [39200/50000]\n",
      "loss: 0.518277  [39600/50000]\n",
      "loss: 0.324158  [40000/50000]\n",
      "loss: 1.236828  [40400/50000]\n",
      "loss: 1.573327  [40800/50000]\n",
      "loss: 0.133219  [41200/50000]\n",
      "loss: 0.449577  [41600/50000]\n",
      "loss: 0.630581  [42000/50000]\n",
      "loss: 1.230105  [42400/50000]\n",
      "loss: 1.547810  [42800/50000]\n",
      "loss: 1.529598  [43200/50000]\n",
      "loss: 0.460016  [43600/50000]\n",
      "loss: 1.523282  [44000/50000]\n",
      "loss: 0.218739  [44400/50000]\n",
      "loss: 1.181340  [44800/50000]\n",
      "loss: 0.897919  [45200/50000]\n",
      "loss: 0.726145  [45600/50000]\n",
      "loss: 0.542834  [46000/50000]\n",
      "loss: 2.471645  [46400/50000]\n",
      "loss: 0.905322  [46800/50000]\n",
      "loss: 1.078340  [47200/50000]\n",
      "loss: 0.620800  [47600/50000]\n",
      "loss: 1.253362  [48000/50000]\n",
      "loss: 0.478395  [48400/50000]\n",
      "loss: 0.768605  [48800/50000]\n",
      "loss: 0.997640  [49200/50000]\n",
      "loss: 0.672679  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.268210 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.861113  [    0/50000]\n",
      "loss: 1.976797  [  400/50000]\n",
      "loss: 0.830875  [  800/50000]\n",
      "loss: 1.940904  [ 1200/50000]\n",
      "loss: 0.774153  [ 1600/50000]\n",
      "loss: 0.452844  [ 2000/50000]\n",
      "loss: 0.528082  [ 2400/50000]\n",
      "loss: 0.251349  [ 2800/50000]\n",
      "loss: 0.792742  [ 3200/50000]\n",
      "loss: 0.331599  [ 3600/50000]\n",
      "loss: 0.508250  [ 4000/50000]\n",
      "loss: 0.986553  [ 4400/50000]\n",
      "loss: 1.043349  [ 4800/50000]\n",
      "loss: 0.978864  [ 5200/50000]\n",
      "loss: 1.163398  [ 5600/50000]\n",
      "loss: 0.803917  [ 6000/50000]\n",
      "loss: 1.079583  [ 6400/50000]\n",
      "loss: 1.307535  [ 6800/50000]\n",
      "loss: 0.574007  [ 7200/50000]\n",
      "loss: 0.684470  [ 7600/50000]\n",
      "loss: 0.794430  [ 8000/50000]\n",
      "loss: 0.490008  [ 8400/50000]\n",
      "loss: 1.203014  [ 8800/50000]\n",
      "loss: 1.402004  [ 9200/50000]\n",
      "loss: 1.377797  [ 9600/50000]\n",
      "loss: 0.233615  [10000/50000]\n",
      "loss: 0.240371  [10400/50000]\n",
      "loss: 1.819646  [10800/50000]\n",
      "loss: 1.573662  [11200/50000]\n",
      "loss: 2.213222  [11600/50000]\n",
      "loss: 1.073169  [12000/50000]\n",
      "loss: 0.052450  [12400/50000]\n",
      "loss: 0.692971  [12800/50000]\n",
      "loss: 1.688219  [13200/50000]\n",
      "loss: 0.787851  [13600/50000]\n",
      "loss: 1.830469  [14000/50000]\n",
      "loss: 1.025573  [14400/50000]\n",
      "loss: 1.213061  [14800/50000]\n",
      "loss: 1.250125  [15200/50000]\n",
      "loss: 1.147088  [15600/50000]\n",
      "loss: 1.143108  [16000/50000]\n",
      "loss: 1.125421  [16400/50000]\n",
      "loss: 1.267484  [16800/50000]\n",
      "loss: 1.122487  [17200/50000]\n",
      "loss: 0.075318  [17600/50000]\n",
      "loss: 0.891341  [18000/50000]\n",
      "loss: 0.326627  [18400/50000]\n",
      "loss: 0.434673  [18800/50000]\n",
      "loss: 0.226060  [19200/50000]\n",
      "loss: 1.277223  [19600/50000]\n",
      "loss: 2.160776  [20000/50000]\n",
      "loss: 1.126984  [20400/50000]\n",
      "loss: 1.678970  [20800/50000]\n",
      "loss: 1.381185  [21200/50000]\n",
      "loss: 0.189115  [21600/50000]\n",
      "loss: 0.626263  [22000/50000]\n",
      "loss: 0.385252  [22400/50000]\n",
      "loss: 0.709228  [22800/50000]\n",
      "loss: 0.743710  [23200/50000]\n",
      "loss: 0.048026  [23600/50000]\n",
      "loss: 0.220917  [24000/50000]\n",
      "loss: 0.286510  [24400/50000]\n",
      "loss: 0.394435  [24800/50000]\n",
      "loss: 1.024613  [25200/50000]\n",
      "loss: 1.581536  [25600/50000]\n",
      "loss: 0.853611  [26000/50000]\n",
      "loss: 1.260521  [26400/50000]\n",
      "loss: 0.864505  [26800/50000]\n",
      "loss: 1.732913  [27200/50000]\n",
      "loss: 1.095011  [27600/50000]\n",
      "loss: 1.705253  [28000/50000]\n",
      "loss: 1.095441  [28400/50000]\n",
      "loss: 1.434957  [28800/50000]\n",
      "loss: 1.991402  [29200/50000]\n",
      "loss: 0.367778  [29600/50000]\n",
      "loss: 1.920060  [30000/50000]\n",
      "loss: 1.254142  [30400/50000]\n",
      "loss: 0.938923  [30800/50000]\n",
      "loss: 1.762398  [31200/50000]\n",
      "loss: 1.282763  [31600/50000]\n",
      "loss: 0.384715  [32000/50000]\n",
      "loss: 0.880594  [32400/50000]\n",
      "loss: 1.535463  [32800/50000]\n",
      "loss: 1.322969  [33200/50000]\n",
      "loss: 0.607243  [33600/50000]\n",
      "loss: 1.915926  [34000/50000]\n",
      "loss: 0.669695  [34400/50000]\n",
      "loss: 0.515215  [34800/50000]\n",
      "loss: 1.665783  [35200/50000]\n",
      "loss: 0.468254  [35600/50000]\n",
      "loss: 1.059425  [36000/50000]\n",
      "loss: 2.033848  [36400/50000]\n",
      "loss: 0.474399  [36800/50000]\n",
      "loss: 0.373424  [37200/50000]\n",
      "loss: 0.230513  [37600/50000]\n",
      "loss: 1.022072  [38000/50000]\n",
      "loss: 0.993132  [38400/50000]\n",
      "loss: 0.194386  [38800/50000]\n",
      "loss: 0.678863  [39200/50000]\n",
      "loss: 0.517118  [39600/50000]\n",
      "loss: 0.323488  [40000/50000]\n",
      "loss: 1.204796  [40400/50000]\n",
      "loss: 1.598575  [40800/50000]\n",
      "loss: 0.126926  [41200/50000]\n",
      "loss: 0.431497  [41600/50000]\n",
      "loss: 0.628675  [42000/50000]\n",
      "loss: 1.211921  [42400/50000]\n",
      "loss: 1.476088  [42800/50000]\n",
      "loss: 1.526754  [43200/50000]\n",
      "loss: 0.484756  [43600/50000]\n",
      "loss: 1.553903  [44000/50000]\n",
      "loss: 0.219016  [44400/50000]\n",
      "loss: 1.115772  [44800/50000]\n",
      "loss: 0.830630  [45200/50000]\n",
      "loss: 0.711052  [45600/50000]\n",
      "loss: 0.520020  [46000/50000]\n",
      "loss: 2.455576  [46400/50000]\n",
      "loss: 0.854456  [46800/50000]\n",
      "loss: 0.957739  [47200/50000]\n",
      "loss: 0.616955  [47600/50000]\n",
      "loss: 1.165350  [48000/50000]\n",
      "loss: 0.465334  [48400/50000]\n",
      "loss: 0.716541  [48800/50000]\n",
      "loss: 0.967676  [49200/50000]\n",
      "loss: 0.601530  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.267116 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.836106  [    0/50000]\n",
      "loss: 1.837446  [  400/50000]\n",
      "loss: 0.796888  [  800/50000]\n",
      "loss: 1.724120  [ 1200/50000]\n",
      "loss: 0.736796  [ 1600/50000]\n",
      "loss: 0.480280  [ 2000/50000]\n",
      "loss: 0.529935  [ 2400/50000]\n",
      "loss: 0.219832  [ 2800/50000]\n",
      "loss: 0.813463  [ 3200/50000]\n",
      "loss: 0.293984  [ 3600/50000]\n",
      "loss: 0.490194  [ 4000/50000]\n",
      "loss: 0.985820  [ 4400/50000]\n",
      "loss: 1.005518  [ 4800/50000]\n",
      "loss: 1.009490  [ 5200/50000]\n",
      "loss: 1.113051  [ 5600/50000]\n",
      "loss: 0.813457  [ 6000/50000]\n",
      "loss: 1.126119  [ 6400/50000]\n",
      "loss: 1.220072  [ 6800/50000]\n",
      "loss: 0.532971  [ 7200/50000]\n",
      "loss: 0.664599  [ 7600/50000]\n",
      "loss: 0.777527  [ 8000/50000]\n",
      "loss: 0.408377  [ 8400/50000]\n",
      "loss: 1.136986  [ 8800/50000]\n",
      "loss: 1.300877  [ 9200/50000]\n",
      "loss: 1.290336  [ 9600/50000]\n",
      "loss: 0.184015  [10000/50000]\n",
      "loss: 0.219387  [10400/50000]\n",
      "loss: 1.802565  [10800/50000]\n",
      "loss: 1.558649  [11200/50000]\n",
      "loss: 2.196285  [11600/50000]\n",
      "loss: 1.025467  [12000/50000]\n",
      "loss: 0.049180  [12400/50000]\n",
      "loss: 0.666242  [12800/50000]\n",
      "loss: 1.763572  [13200/50000]\n",
      "loss: 0.731409  [13600/50000]\n",
      "loss: 1.797668  [14000/50000]\n",
      "loss: 1.014949  [14400/50000]\n",
      "loss: 1.213157  [14800/50000]\n",
      "loss: 1.192266  [15200/50000]\n",
      "loss: 1.079392  [15600/50000]\n",
      "loss: 1.129153  [16000/50000]\n",
      "loss: 1.115417  [16400/50000]\n",
      "loss: 1.176391  [16800/50000]\n",
      "loss: 1.057003  [17200/50000]\n",
      "loss: 0.063037  [17600/50000]\n",
      "loss: 0.822065  [18000/50000]\n",
      "loss: 0.289785  [18400/50000]\n",
      "loss: 0.390781  [18800/50000]\n",
      "loss: 0.238293  [19200/50000]\n",
      "loss: 1.258442  [19600/50000]\n",
      "loss: 2.159735  [20000/50000]\n",
      "loss: 1.090745  [20400/50000]\n",
      "loss: 1.608152  [20800/50000]\n",
      "loss: 1.317312  [21200/50000]\n",
      "loss: 0.163463  [21600/50000]\n",
      "loss: 0.660776  [22000/50000]\n",
      "loss: 0.360697  [22400/50000]\n",
      "loss: 0.665131  [22800/50000]\n",
      "loss: 0.730333  [23200/50000]\n",
      "loss: 0.039219  [23600/50000]\n",
      "loss: 0.199804  [24000/50000]\n",
      "loss: 0.273674  [24400/50000]\n",
      "loss: 0.364277  [24800/50000]\n",
      "loss: 1.002621  [25200/50000]\n",
      "loss: 1.596199  [25600/50000]\n",
      "loss: 0.833060  [26000/50000]\n",
      "loss: 1.194721  [26400/50000]\n",
      "loss: 0.824759  [26800/50000]\n",
      "loss: 1.653332  [27200/50000]\n",
      "loss: 0.978129  [27600/50000]\n",
      "loss: 1.655078  [28000/50000]\n",
      "loss: 1.066665  [28400/50000]\n",
      "loss: 1.434515  [28800/50000]\n",
      "loss: 1.960935  [29200/50000]\n",
      "loss: 0.378103  [29600/50000]\n",
      "loss: 2.010412  [30000/50000]\n",
      "loss: 1.246167  [30400/50000]\n",
      "loss: 0.901294  [30800/50000]\n",
      "loss: 1.715832  [31200/50000]\n",
      "loss: 1.290791  [31600/50000]\n",
      "loss: 0.397143  [32000/50000]\n",
      "loss: 0.881292  [32400/50000]\n",
      "loss: 1.516262  [32800/50000]\n",
      "loss: 1.308348  [33200/50000]\n",
      "loss: 0.614408  [33600/50000]\n",
      "loss: 1.862506  [34000/50000]\n",
      "loss: 0.631712  [34400/50000]\n",
      "loss: 0.512137  [34800/50000]\n",
      "loss: 1.602946  [35200/50000]\n",
      "loss: 0.443980  [35600/50000]\n",
      "loss: 1.044594  [36000/50000]\n",
      "loss: 1.946047  [36400/50000]\n",
      "loss: 0.470073  [36800/50000]\n",
      "loss: 0.376075  [37200/50000]\n",
      "loss: 0.222559  [37600/50000]\n",
      "loss: 0.968709  [38000/50000]\n",
      "loss: 0.970287  [38400/50000]\n",
      "loss: 0.163927  [38800/50000]\n",
      "loss: 0.616313  [39200/50000]\n",
      "loss: 0.525702  [39600/50000]\n",
      "loss: 0.320421  [40000/50000]\n",
      "loss: 1.179333  [40400/50000]\n",
      "loss: 1.552959  [40800/50000]\n",
      "loss: 0.125883  [41200/50000]\n",
      "loss: 0.406939  [41600/50000]\n",
      "loss: 0.651712  [42000/50000]\n",
      "loss: 1.243274  [42400/50000]\n",
      "loss: 1.447869  [42800/50000]\n",
      "loss: 1.490357  [43200/50000]\n",
      "loss: 0.488906  [43600/50000]\n",
      "loss: 1.474682  [44000/50000]\n",
      "loss: 0.215154  [44400/50000]\n",
      "loss: 1.119096  [44800/50000]\n",
      "loss: 0.769756  [45200/50000]\n",
      "loss: 0.703504  [45600/50000]\n",
      "loss: 0.517528  [46000/50000]\n",
      "loss: 2.383773  [46400/50000]\n",
      "loss: 0.825126  [46800/50000]\n",
      "loss: 0.880911  [47200/50000]\n",
      "loss: 0.626245  [47600/50000]\n",
      "loss: 1.129758  [48000/50000]\n",
      "loss: 0.465133  [48400/50000]\n",
      "loss: 0.672686  [48800/50000]\n",
      "loss: 0.957735  [49200/50000]\n",
      "loss: 0.562573  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.265014 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.803600  [    0/50000]\n",
      "loss: 1.805811  [  400/50000]\n",
      "loss: 0.783124  [  800/50000]\n",
      "loss: 1.662589  [ 1200/50000]\n",
      "loss: 0.719750  [ 1600/50000]\n",
      "loss: 0.496476  [ 2000/50000]\n",
      "loss: 0.530084  [ 2400/50000]\n",
      "loss: 0.221150  [ 2800/50000]\n",
      "loss: 0.773590  [ 3200/50000]\n",
      "loss: 0.269949  [ 3600/50000]\n",
      "loss: 0.467279  [ 4000/50000]\n",
      "loss: 0.948632  [ 4400/50000]\n",
      "loss: 0.934634  [ 4800/50000]\n",
      "loss: 0.990390  [ 5200/50000]\n",
      "loss: 1.054592  [ 5600/50000]\n",
      "loss: 0.766410  [ 6000/50000]\n",
      "loss: 1.098538  [ 6400/50000]\n",
      "loss: 1.216721  [ 6800/50000]\n",
      "loss: 0.494276  [ 7200/50000]\n",
      "loss: 0.636001  [ 7600/50000]\n",
      "loss: 0.755451  [ 8000/50000]\n",
      "loss: 0.362574  [ 8400/50000]\n",
      "loss: 1.005313  [ 8800/50000]\n",
      "loss: 1.311020  [ 9200/50000]\n",
      "loss: 1.242881  [ 9600/50000]\n",
      "loss: 0.160918  [10000/50000]\n",
      "loss: 0.199309  [10400/50000]\n",
      "loss: 1.784715  [10800/50000]\n",
      "loss: 1.532729  [11200/50000]\n",
      "loss: 2.176824  [11600/50000]\n",
      "loss: 1.108703  [12000/50000]\n",
      "loss: 0.051072  [12400/50000]\n",
      "loss: 0.619788  [12800/50000]\n",
      "loss: 1.809685  [13200/50000]\n",
      "loss: 0.640861  [13600/50000]\n",
      "loss: 1.783505  [14000/50000]\n",
      "loss: 1.027083  [14400/50000]\n",
      "loss: 1.238562  [14800/50000]\n",
      "loss: 1.177284  [15200/50000]\n",
      "loss: 1.083753  [15600/50000]\n",
      "loss: 1.135932  [16000/50000]\n",
      "loss: 1.041233  [16400/50000]\n",
      "loss: 1.187509  [16800/50000]\n",
      "loss: 0.971885  [17200/50000]\n",
      "loss: 0.052670  [17600/50000]\n",
      "loss: 0.796484  [18000/50000]\n",
      "loss: 0.271385  [18400/50000]\n",
      "loss: 0.426590  [18800/50000]\n",
      "loss: 0.256437  [19200/50000]\n",
      "loss: 1.298786  [19600/50000]\n",
      "loss: 2.120322  [20000/50000]\n",
      "loss: 1.081563  [20400/50000]\n",
      "loss: 1.513000  [20800/50000]\n",
      "loss: 1.268450  [21200/50000]\n",
      "loss: 0.150289  [21600/50000]\n",
      "loss: 0.687582  [22000/50000]\n",
      "loss: 0.320739  [22400/50000]\n",
      "loss: 0.614887  [22800/50000]\n",
      "loss: 0.726625  [23200/50000]\n",
      "loss: 0.034889  [23600/50000]\n",
      "loss: 0.188248  [24000/50000]\n",
      "loss: 0.276819  [24400/50000]\n",
      "loss: 0.327294  [24800/50000]\n",
      "loss: 1.012674  [25200/50000]\n",
      "loss: 1.683386  [25600/50000]\n",
      "loss: 0.819420  [26000/50000]\n",
      "loss: 1.087288  [26400/50000]\n",
      "loss: 0.737817  [26800/50000]\n",
      "loss: 1.620184  [27200/50000]\n",
      "loss: 0.925467  [27600/50000]\n",
      "loss: 1.638982  [28000/50000]\n",
      "loss: 1.081435  [28400/50000]\n",
      "loss: 1.496648  [28800/50000]\n",
      "loss: 1.780797  [29200/50000]\n",
      "loss: 0.346461  [29600/50000]\n",
      "loss: 1.996919  [30000/50000]\n",
      "loss: 1.252918  [30400/50000]\n",
      "loss: 0.877692  [30800/50000]\n",
      "loss: 1.688146  [31200/50000]\n",
      "loss: 1.235242  [31600/50000]\n",
      "loss: 0.402177  [32000/50000]\n",
      "loss: 0.883416  [32400/50000]\n",
      "loss: 1.408948  [32800/50000]\n",
      "loss: 1.318383  [33200/50000]\n",
      "loss: 0.625796  [33600/50000]\n",
      "loss: 1.789418  [34000/50000]\n",
      "loss: 0.598566  [34400/50000]\n",
      "loss: 0.487999  [34800/50000]\n",
      "loss: 1.588104  [35200/50000]\n",
      "loss: 0.432507  [35600/50000]\n",
      "loss: 1.030210  [36000/50000]\n",
      "loss: 1.954366  [36400/50000]\n",
      "loss: 0.454837  [36800/50000]\n",
      "loss: 0.390443  [37200/50000]\n",
      "loss: 0.211006  [37600/50000]\n",
      "loss: 0.952238  [38000/50000]\n",
      "loss: 0.941765  [38400/50000]\n",
      "loss: 0.152115  [38800/50000]\n",
      "loss: 0.617565  [39200/50000]\n",
      "loss: 0.542808  [39600/50000]\n",
      "loss: 0.299699  [40000/50000]\n",
      "loss: 1.164732  [40400/50000]\n",
      "loss: 1.557801  [40800/50000]\n",
      "loss: 0.117549  [41200/50000]\n",
      "loss: 0.428487  [41600/50000]\n",
      "loss: 0.647943  [42000/50000]\n",
      "loss: 1.257731  [42400/50000]\n",
      "loss: 1.395956  [42800/50000]\n",
      "loss: 1.442366  [43200/50000]\n",
      "loss: 0.493032  [43600/50000]\n",
      "loss: 1.428586  [44000/50000]\n",
      "loss: 0.214552  [44400/50000]\n",
      "loss: 1.096483  [44800/50000]\n",
      "loss: 0.766594  [45200/50000]\n",
      "loss: 0.683003  [45600/50000]\n",
      "loss: 0.494270  [46000/50000]\n",
      "loss: 2.325289  [46400/50000]\n",
      "loss: 0.792300  [46800/50000]\n",
      "loss: 0.816722  [47200/50000]\n",
      "loss: 0.618725  [47600/50000]\n",
      "loss: 1.132773  [48000/50000]\n",
      "loss: 0.487690  [48400/50000]\n",
      "loss: 0.655207  [48800/50000]\n",
      "loss: 0.925467  [49200/50000]\n",
      "loss: 0.493738  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.264412 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "PATH = './model/cnn_cifar.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  cat   ship  ship  plane\n",
      "Predicted:  cat   car   truck plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# テストデータでの評価\n",
    "dataiter = iter(test_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "model = CNN()\n",
    "# 保存した状態辞書をロード\n",
    "model.load_state_dict(torch.load('../model/cnn_cifar.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 画像の表示\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # デノーマライズ\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    # plt.axis('off')  # 軸を非表示にする\n",
    "    plt.show()\n",
    "\n",
    "# 出力の表示\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))\n",
    "\n",
    "# 画像を表示\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
